{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1993, 4862) (1993,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "basehock_mat = loadmat('BASEHOCK.mat')\n",
    "basehock_X = basehock_mat['X']\n",
    "basehock_y = basehock_mat['Y']\n",
    "basehock_X = basehock_X.todense()\n",
    "basehock_y = basehock_y.flatten()\n",
    "print(basehock_X.shape, basehock_y.shape)\n",
    "basehock_y[np.where(basehock_y==1)] = 0\n",
    "basehock_y[np.where(basehock_y==2)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No feature selection baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: Feature Index 0-2430\n",
      "Server : Feature Index 2431-4861\n",
      "Training Starts\n",
      "Number of Clients: 1\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: | Loss: 0.62726 | Acc: 0.631 | Val ACC: 0.930\n",
      "Epoch 001: | Loss: 0.13662 | Acc: 0.981 | Val ACC: 0.965\n",
      "Epoch 002: | Loss: 0.00888 | Acc: 0.998 | Val ACC: 0.972\n",
      "Epoch 003: | Loss: 0.00300 | Acc: 0.999 | Val ACC: 0.965\n",
      "Epoch 004: | Loss: 0.00585 | Acc: 0.999 | Val ACC: 0.977\n",
      "Epoch 005: | Loss: 0.00043 | Acc: 1.000 | Val ACC: 0.972\n",
      "Epoch 006: | Loss: 0.00016 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 007: | Loss: 0.00030 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 008: | Loss: 0.00045 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 009: | Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 010: | Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 011: | Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 012: | Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 013: | Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 014: | Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 015: | Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 016: | Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 017: | Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 018: | Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 019: | Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 020: | Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 021: | Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 022: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 023: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 024: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 025: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 026: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 027: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 028: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 029: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 030: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 031: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 032: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 033: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 034: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 035: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 036: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 037: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 038: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 039: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 040: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 041: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 042: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 043: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.980\n",
      "Epoch 044: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 045: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 046: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 047: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 048: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 049: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 050: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 051: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 052: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 053: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 054: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 055: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 056: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 057: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 058: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 059: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 060: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 061: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 062: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 063: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 064: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 065: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 066: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 067: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 068: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 069: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 070: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 071: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 072: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 073: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 074: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 075: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 076: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 077: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 078: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 079: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 080: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 081: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 082: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 083: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 084: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 085: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 086: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 087: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 088: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 089: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 090: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 091: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 092: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 093: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 094: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 095: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 096: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 097: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 098: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Epoch 099: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.977\n",
      "Client 0: Feature Index 0-1620\n",
      "Client 1: Feature Index 1621-3241\n",
      "Server : Feature Index 3242-4861\n",
      "Training Starts\n",
      "Number of Clients: 2\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: | Loss: 0.65975 | Acc: 0.654 | Val ACC: 0.897\n",
      "Epoch 001: | Loss: 0.25400 | Acc: 0.961 | Val ACC: 0.950\n",
      "Epoch 002: | Loss: 0.03867 | Acc: 0.987 | Val ACC: 0.940\n",
      "Epoch 003: | Loss: 0.02425 | Acc: 0.994 | Val ACC: 0.910\n",
      "Epoch 004: | Loss: 0.03574 | Acc: 0.988 | Val ACC: 0.920\n",
      "Epoch 005: | Loss: 0.10885 | Acc: 0.968 | Val ACC: 0.932\n",
      "Epoch 006: | Loss: 0.12382 | Acc: 0.987 | Val ACC: 0.940\n",
      "Epoch 007: | Loss: 0.00809 | Acc: 0.999 | Val ACC: 0.942\n",
      "Epoch 008: | Loss: 0.00798 | Acc: 0.999 | Val ACC: 0.947\n",
      "Epoch 009: | Loss: 0.00441 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 010: | Loss: 0.00324 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 011: | Loss: 0.00244 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 012: | Loss: 0.00191 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 013: | Loss: 0.00155 | Acc: 1.000 | Val ACC: 0.950\n",
      "Epoch 014: | Loss: 0.00128 | Acc: 1.000 | Val ACC: 0.950\n",
      "Epoch 015: | Loss: 0.00108 | Acc: 1.000 | Val ACC: 0.950\n",
      "Epoch 016: | Loss: 0.00093 | Acc: 1.000 | Val ACC: 0.950\n",
      "Epoch 017: | Loss: 0.00081 | Acc: 1.000 | Val ACC: 0.950\n",
      "Epoch 018: | Loss: 0.00071 | Acc: 1.000 | Val ACC: 0.950\n",
      "Epoch 019: | Loss: 0.00063 | Acc: 1.000 | Val ACC: 0.950\n",
      "Epoch 020: | Loss: 0.00056 | Acc: 1.000 | Val ACC: 0.950\n",
      "Epoch 021: | Loss: 0.00050 | Acc: 1.000 | Val ACC: 0.950\n",
      "Epoch 022: | Loss: 0.00045 | Acc: 1.000 | Val ACC: 0.950\n",
      "Epoch 023: | Loss: 0.00041 | Acc: 1.000 | Val ACC: 0.950\n",
      "Epoch 024: | Loss: 0.00037 | Acc: 1.000 | Val ACC: 0.950\n",
      "Epoch 025: | Loss: 0.00034 | Acc: 1.000 | Val ACC: 0.950\n",
      "Epoch 026: | Loss: 0.00031 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 027: | Loss: 0.00029 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 028: | Loss: 0.00027 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 029: | Loss: 0.00025 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 030: | Loss: 0.00023 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 031: | Loss: 0.00021 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 032: | Loss: 0.00020 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 033: | Loss: 0.00019 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 034: | Loss: 0.00018 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 035: | Loss: 0.00016 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 036: | Loss: 0.00015 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 037: | Loss: 0.00015 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 038: | Loss: 0.00014 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 039: | Loss: 0.00013 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 040: | Loss: 0.00012 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 041: | Loss: 0.00012 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 042: | Loss: 0.00011 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 043: | Loss: 0.00011 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 044: | Loss: 0.00010 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 045: | Loss: 0.00010 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 046: | Loss: 0.00009 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 047: | Loss: 0.00009 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 048: | Loss: 0.00008 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 049: | Loss: 0.00008 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 050: | Loss: 0.00008 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 051: | Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 052: | Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 053: | Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 054: | Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 055: | Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.945\n",
      "Epoch 056: | Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 057: | Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 058: | Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 059: | Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 060: | Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 061: | Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 062: | Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 063: | Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 064: | Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 065: | Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 066: | Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 067: | Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 068: | Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.947\n",
      "Epoch 069: | Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.942\n",
      "Epoch 070: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.940\n",
      "Epoch 071: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.940\n",
      "Epoch 072: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 073: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 074: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 075: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 076: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 077: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 078: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 079: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 080: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 081: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 082: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 083: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 084: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 085: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 086: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 087: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 088: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 089: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 090: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 091: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 092: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 093: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 094: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 095: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 096: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 097: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 098: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Epoch 099: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.935\n",
      "Client 0: Feature Index 0-1215\n",
      "Client 1: Feature Index 1216-2431\n",
      "Client 2: Feature Index 2432-3646\n",
      "Server : Feature Index 3647-4861\n",
      "Training Starts\n",
      "Number of Clients: 3\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: | Loss: 0.66583 | Acc: 0.660 | Val ACC: 0.890\n",
      "Epoch 001: | Loss: 0.30236 | Acc: 0.934 | Val ACC: 0.927\n",
      "Epoch 002: | Loss: 0.07922 | Acc: 0.975 | Val ACC: 0.902\n",
      "Epoch 003: | Loss: 0.06911 | Acc: 0.976 | Val ACC: 0.895\n",
      "Epoch 004: | Loss: 0.08635 | Acc: 0.970 | Val ACC: 0.910\n",
      "Epoch 005: | Loss: 0.06058 | Acc: 0.983 | Val ACC: 0.902\n",
      "Epoch 006: | Loss: 0.02500 | Acc: 0.992 | Val ACC: 0.912\n",
      "Epoch 007: | Loss: 0.01072 | Acc: 0.999 | Val ACC: 0.917\n",
      "Epoch 008: | Loss: 0.00716 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 009: | Loss: 0.00449 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 010: | Loss: 0.00305 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 011: | Loss: 0.00220 | Acc: 1.000 | Val ACC: 0.922\n",
      "Epoch 012: | Loss: 0.00168 | Acc: 1.000 | Val ACC: 0.922\n",
      "Epoch 013: | Loss: 0.00134 | Acc: 1.000 | Val ACC: 0.922\n",
      "Epoch 014: | Loss: 0.00110 | Acc: 1.000 | Val ACC: 0.922\n",
      "Epoch 015: | Loss: 0.00093 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 016: | Loss: 0.00080 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 017: | Loss: 0.00069 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 018: | Loss: 0.00061 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 019: | Loss: 0.00054 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 020: | Loss: 0.00048 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 021: | Loss: 0.00043 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 022: | Loss: 0.00039 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 023: | Loss: 0.00035 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 024: | Loss: 0.00032 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 025: | Loss: 0.00030 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 026: | Loss: 0.00027 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 027: | Loss: 0.00025 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 028: | Loss: 0.00023 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 029: | Loss: 0.00022 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 030: | Loss: 0.00020 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 031: | Loss: 0.00019 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 032: | Loss: 0.00017 | Acc: 1.000 | Val ACC: 0.917\n",
      "Epoch 033: | Loss: 0.00016 | Acc: 1.000 | Val ACC: 0.917\n",
      "Epoch 034: | Loss: 0.00015 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 035: | Loss: 0.00014 | Acc: 1.000 | Val ACC: 0.920\n",
      "Epoch 036: | Loss: 0.00014 | Acc: 1.000 | Val ACC: 0.917\n",
      "Epoch 037: | Loss: 0.00012 | Acc: 1.000 | Val ACC: 0.915\n",
      "Epoch 038: | Loss: 0.00010 | Acc: 1.000 | Val ACC: 0.912\n",
      "Epoch 039: | Loss: 0.00008 | Acc: 1.000 | Val ACC: 0.912\n",
      "Epoch 040: | Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.910\n",
      "Epoch 041: | Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.910\n",
      "Epoch 042: | Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.910\n",
      "Epoch 043: | Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.910\n",
      "Epoch 044: | Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.910\n",
      "Epoch 045: | Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.910\n",
      "Epoch 046: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.910\n",
      "Epoch 047: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.905\n",
      "Epoch 048: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 049: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 050: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 051: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 052: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 053: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 054: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 055: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 056: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 057: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 058: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 059: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 060: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 061: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 062: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 063: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 064: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 065: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 066: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 067: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 068: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 069: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 070: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 071: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 072: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 073: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 074: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 075: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 076: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 077: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 078: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 079: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 080: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 081: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 082: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 083: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 084: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 085: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 086: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 087: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 088: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 089: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 090: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 091: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 092: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 093: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 094: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 095: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 096: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 097: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902\n",
      "Epoch 098: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.900\n",
      "Epoch 099: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.900\n",
      "Client 0: Feature Index 0-972\n",
      "Client 1: Feature Index 973-1945\n",
      "Client 2: Feature Index 1946-2917\n",
      "Client 3: Feature Index 2918-3889\n",
      "Server : Feature Index 3890-4861\n",
      "Training Starts\n",
      "Number of Clients: 4\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: | Loss: 0.67702 | Acc: 0.574 | Val ACC: 0.857\n",
      "Epoch 001: | Loss: 0.38467 | Acc: 0.909 | Val ACC: 0.902\n",
      "Epoch 002: | Loss: 0.10976 | Acc: 0.958 | Val ACC: 0.907\n",
      "Epoch 003: | Loss: 0.07355 | Acc: 0.974 | Val ACC: 0.905\n",
      "Epoch 004: | Loss: 0.05203 | Acc: 0.977 | Val ACC: 0.867\n",
      "Epoch 005: | Loss: 0.13389 | Acc: 0.948 | Val ACC: 0.895\n",
      "Epoch 006: | Loss: 0.19568 | Acc: 0.956 | Val ACC: 0.895\n",
      "Epoch 007: | Loss: 0.06481 | Acc: 0.977 | Val ACC: 0.897\n",
      "Epoch 008: | Loss: 0.03467 | Acc: 0.989 | Val ACC: 0.905\n",
      "Epoch 009: | Loss: 0.02404 | Acc: 0.993 | Val ACC: 0.900\n",
      "Epoch 010: | Loss: 0.01610 | Acc: 0.995 | Val ACC: 0.900\n",
      "Epoch 011: | Loss: 0.01129 | Acc: 0.996 | Val ACC: 0.902\n",
      "Epoch 012: | Loss: 0.00908 | Acc: 0.998 | Val ACC: 0.905\n",
      "Epoch 013: | Loss: 0.00757 | Acc: 0.998 | Val ACC: 0.905\n",
      "Epoch 014: | Loss: 0.00661 | Acc: 0.998 | Val ACC: 0.905\n",
      "Epoch 015: | Loss: 0.00596 | Acc: 0.998 | Val ACC: 0.905\n",
      "Epoch 016: | Loss: 0.00547 | Acc: 0.998 | Val ACC: 0.905\n",
      "Epoch 017: | Loss: 0.00512 | Acc: 0.998 | Val ACC: 0.905\n",
      "Epoch 018: | Loss: 0.00483 | Acc: 0.998 | Val ACC: 0.905\n",
      "Epoch 019: | Loss: 0.00461 | Acc: 0.998 | Val ACC: 0.905\n",
      "Epoch 020: | Loss: 0.00443 | Acc: 0.998 | Val ACC: 0.905\n",
      "Epoch 021: | Loss: 0.00427 | Acc: 0.998 | Val ACC: 0.907\n",
      "Epoch 022: | Loss: 0.00415 | Acc: 0.998 | Val ACC: 0.907\n",
      "Epoch 023: | Loss: 0.00402 | Acc: 0.998 | Val ACC: 0.907\n",
      "Epoch 024: | Loss: 0.00392 | Acc: 0.998 | Val ACC: 0.910\n",
      "Epoch 025: | Loss: 0.00382 | Acc: 0.998 | Val ACC: 0.910\n",
      "Epoch 026: | Loss: 0.00371 | Acc: 0.998 | Val ACC: 0.910\n",
      "Epoch 027: | Loss: 0.00363 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 028: | Loss: 0.00356 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 029: | Loss: 0.00345 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 030: | Loss: 0.00339 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 031: | Loss: 0.00328 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 032: | Loss: 0.00323 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 033: | Loss: 0.00312 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 034: | Loss: 0.00308 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 035: | Loss: 0.00297 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 036: | Loss: 0.00291 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 037: | Loss: 0.00283 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 038: | Loss: 0.00276 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 039: | Loss: 0.00268 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 040: | Loss: 0.00262 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 041: | Loss: 0.00255 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 042: | Loss: 0.00248 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 043: | Loss: 0.00241 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 044: | Loss: 0.00238 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 045: | Loss: 0.00226 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 046: | Loss: 0.00224 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 047: | Loss: 0.00214 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 048: | Loss: 0.00215 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 049: | Loss: 0.00203 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 050: | Loss: 0.00207 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 051: | Loss: 0.00192 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 052: | Loss: 0.00200 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 053: | Loss: 0.00181 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 054: | Loss: 0.00197 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 055: | Loss: 0.00170 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 056: | Loss: 0.00201 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 057: | Loss: 0.00157 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 058: | Loss: 0.00226 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 059: | Loss: 0.00144 | Acc: 1.000 | Val ACC: 0.907\n",
      "Epoch 060: | Loss: 0.00311 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 061: | Loss: 0.00145 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 062: | Loss: 0.00511 | Acc: 0.998 | Val ACC: 0.907\n",
      "Epoch 063: | Loss: 0.00146 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 064: | Loss: 0.00673 | Acc: 0.998 | Val ACC: 0.910\n",
      "Epoch 065: | Loss: 0.00124 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 066: | Loss: 0.00328 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 067: | Loss: 0.00116 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 068: | Loss: 0.00224 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 069: | Loss: 0.00125 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 070: | Loss: 0.00226 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 071: | Loss: 0.00121 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 072: | Loss: 0.00286 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 073: | Loss: 0.00114 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 074: | Loss: 0.00320 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 075: | Loss: 0.00105 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 076: | Loss: 0.00282 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 077: | Loss: 0.00108 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 078: | Loss: 0.00273 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 079: | Loss: 0.00108 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 080: | Loss: 0.00274 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 081: | Loss: 0.00107 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 082: | Loss: 0.00277 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 083: | Loss: 0.00107 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 084: | Loss: 0.00282 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 085: | Loss: 0.00105 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 086: | Loss: 0.00273 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 087: | Loss: 0.00105 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 088: | Loss: 0.00268 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 089: | Loss: 0.00105 | Acc: 0.999 | Val ACC: 0.910\n",
      "Epoch 090: | Loss: 0.00269 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 091: | Loss: 0.00104 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 092: | Loss: 0.00265 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 093: | Loss: 0.00104 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 094: | Loss: 0.00260 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 095: | Loss: 0.00104 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 096: | Loss: 0.00261 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 097: | Loss: 0.00103 | Acc: 0.999 | Val ACC: 0.912\n",
      "Epoch 098: | Loss: 0.00255 | Acc: 0.999 | Val ACC: 0.907\n",
      "Epoch 099: | Loss: 0.00103 | Acc: 0.999 | Val ACC: 0.912\n",
      "Client 0: Feature Index 0-810\n",
      "Client 1: Feature Index 811-1621\n",
      "Client 2: Feature Index 1622-2431\n",
      "Client 3: Feature Index 2432-3241\n",
      "Client 4: Feature Index 3242-4051\n",
      "Server : Feature Index 4052-4861\n",
      "Training Starts\n",
      "Number of Clients: 5\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: | Loss: 0.68415 | Acc: 0.538 | Val ACC: 0.792\n",
      "Epoch 001: | Loss: 0.43867 | Acc: 0.877 | Val ACC: 0.870\n",
      "Epoch 002: | Loss: 0.14852 | Acc: 0.938 | Val ACC: 0.867\n",
      "Epoch 003: | Loss: 0.09058 | Acc: 0.963 | Val ACC: 0.865\n",
      "Epoch 004: | Loss: 0.06157 | Acc: 0.975 | Val ACC: 0.840\n",
      "Epoch 005: | Loss: 0.08729 | Acc: 0.965 | Val ACC: 0.845\n",
      "Epoch 006: | Loss: 0.24513 | Acc: 0.933 | Val ACC: 0.857\n",
      "Epoch 007: | Loss: 0.08820 | Acc: 0.970 | Val ACC: 0.862\n",
      "Epoch 008: | Loss: 0.05816 | Acc: 0.985 | Val ACC: 0.882\n",
      "Epoch 009: | Loss: 0.03494 | Acc: 0.990 | Val ACC: 0.885\n",
      "Epoch 010: | Loss: 0.02232 | Acc: 0.993 | Val ACC: 0.885\n",
      "Epoch 011: | Loss: 0.01649 | Acc: 0.996 | Val ACC: 0.880\n",
      "Epoch 012: | Loss: 0.01218 | Acc: 0.996 | Val ACC: 0.882\n",
      "Epoch 013: | Loss: 0.01026 | Acc: 0.997 | Val ACC: 0.885\n",
      "Epoch 014: | Loss: 0.00864 | Acc: 0.998 | Val ACC: 0.882\n",
      "Epoch 015: | Loss: 0.00788 | Acc: 0.998 | Val ACC: 0.880\n",
      "Epoch 016: | Loss: 0.00716 | Acc: 0.998 | Val ACC: 0.880\n",
      "Epoch 017: | Loss: 0.00666 | Acc: 0.998 | Val ACC: 0.882\n",
      "Epoch 018: | Loss: 0.00627 | Acc: 0.998 | Val ACC: 0.882\n",
      "Epoch 019: | Loss: 0.00592 | Acc: 0.998 | Val ACC: 0.885\n",
      "Epoch 020: | Loss: 0.00566 | Acc: 0.998 | Val ACC: 0.887\n",
      "Epoch 021: | Loss: 0.00542 | Acc: 0.998 | Val ACC: 0.887\n",
      "Epoch 022: | Loss: 0.00522 | Acc: 0.998 | Val ACC: 0.890\n",
      "Epoch 023: | Loss: 0.00503 | Acc: 0.998 | Val ACC: 0.890\n",
      "Epoch 024: | Loss: 0.00485 | Acc: 0.998 | Val ACC: 0.890\n",
      "Epoch 025: | Loss: 0.00472 | Acc: 0.998 | Val ACC: 0.892\n",
      "Epoch 026: | Loss: 0.00457 | Acc: 0.998 | Val ACC: 0.892\n",
      "Epoch 027: | Loss: 0.00445 | Acc: 0.998 | Val ACC: 0.892\n",
      "Epoch 028: | Loss: 0.00432 | Acc: 0.999 | Val ACC: 0.892\n",
      "Epoch 029: | Loss: 0.00424 | Acc: 0.999 | Val ACC: 0.892\n",
      "Epoch 030: | Loss: 0.00411 | Acc: 0.999 | Val ACC: 0.892\n",
      "Epoch 031: | Loss: 0.00403 | Acc: 0.999 | Val ACC: 0.892\n",
      "Epoch 032: | Loss: 0.00394 | Acc: 0.999 | Val ACC: 0.892\n",
      "Epoch 033: | Loss: 0.00386 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 034: | Loss: 0.00376 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 035: | Loss: 0.00370 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 036: | Loss: 0.00365 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 037: | Loss: 0.00357 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 038: | Loss: 0.00353 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 039: | Loss: 0.00347 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 040: | Loss: 0.00342 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 041: | Loss: 0.00337 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 042: | Loss: 0.00335 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 043: | Loss: 0.00327 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 044: | Loss: 0.00328 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 045: | Loss: 0.00321 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 046: | Loss: 0.00326 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 047: | Loss: 0.00311 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 048: | Loss: 0.00326 | Acc: 0.998 | Val ACC: 0.897\n",
      "Epoch 049: | Loss: 0.00301 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 050: | Loss: 0.00339 | Acc: 0.999 | Val ACC: 0.897\n",
      "Epoch 051: | Loss: 0.00294 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 052: | Loss: 0.00399 | Acc: 0.999 | Val ACC: 0.897\n",
      "Epoch 053: | Loss: 0.00311 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 054: | Loss: 0.00608 | Acc: 0.998 | Val ACC: 0.892\n",
      "Epoch 055: | Loss: 0.00371 | Acc: 0.998 | Val ACC: 0.892\n",
      "Epoch 056: | Loss: 0.00879 | Acc: 0.998 | Val ACC: 0.890\n",
      "Epoch 057: | Loss: 0.00323 | Acc: 0.999 | Val ACC: 0.897\n",
      "Epoch 058: | Loss: 0.00726 | Acc: 0.998 | Val ACC: 0.890\n",
      "Epoch 059: | Loss: 0.00344 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 060: | Loss: 0.00656 | Acc: 0.998 | Val ACC: 0.887\n",
      "Epoch 061: | Loss: 0.00311 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 062: | Loss: 0.00372 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 063: | Loss: 0.00292 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 064: | Loss: 0.00409 | Acc: 0.999 | Val ACC: 0.897\n",
      "Epoch 065: | Loss: 0.00299 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 066: | Loss: 0.00512 | Acc: 0.999 | Val ACC: 0.887\n",
      "Epoch 067: | Loss: 0.00308 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 068: | Loss: 0.00538 | Acc: 0.999 | Val ACC: 0.887\n",
      "Epoch 069: | Loss: 0.00291 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 070: | Loss: 0.00459 | Acc: 0.999 | Val ACC: 0.885\n",
      "Epoch 071: | Loss: 0.00278 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 072: | Loss: 0.00427 | Acc: 0.999 | Val ACC: 0.885\n",
      "Epoch 073: | Loss: 0.00280 | Acc: 0.998 | Val ACC: 0.897\n",
      "Epoch 074: | Loss: 0.00438 | Acc: 0.999 | Val ACC: 0.887\n",
      "Epoch 075: | Loss: 0.00280 | Acc: 0.998 | Val ACC: 0.897\n",
      "Epoch 076: | Loss: 0.00434 | Acc: 0.999 | Val ACC: 0.887\n",
      "Epoch 077: | Loss: 0.00277 | Acc: 0.998 | Val ACC: 0.897\n",
      "Epoch 078: | Loss: 0.00423 | Acc: 0.999 | Val ACC: 0.887\n",
      "Epoch 079: | Loss: 0.00274 | Acc: 0.999 | Val ACC: 0.897\n",
      "Epoch 080: | Loss: 0.00418 | Acc: 0.999 | Val ACC: 0.887\n",
      "Epoch 081: | Loss: 0.00272 | Acc: 0.999 | Val ACC: 0.897\n",
      "Epoch 082: | Loss: 0.00411 | Acc: 0.999 | Val ACC: 0.887\n",
      "Epoch 083: | Loss: 0.00269 | Acc: 0.998 | Val ACC: 0.895\n",
      "Epoch 084: | Loss: 0.00399 | Acc: 0.999 | Val ACC: 0.887\n",
      "Epoch 085: | Loss: 0.00265 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 086: | Loss: 0.00390 | Acc: 0.999 | Val ACC: 0.887\n",
      "Epoch 087: | Loss: 0.00264 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 088: | Loss: 0.00384 | Acc: 0.999 | Val ACC: 0.887\n",
      "Epoch 089: | Loss: 0.00263 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 090: | Loss: 0.00382 | Acc: 0.999 | Val ACC: 0.890\n",
      "Epoch 091: | Loss: 0.00262 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 092: | Loss: 0.00377 | Acc: 0.999 | Val ACC: 0.890\n",
      "Epoch 093: | Loss: 0.00260 | Acc: 0.999 | Val ACC: 0.895\n",
      "Epoch 094: | Loss: 0.00371 | Acc: 0.999 | Val ACC: 0.890\n",
      "Epoch 095: | Loss: 0.00260 | Acc: 0.999 | Val ACC: 0.890\n",
      "Epoch 096: | Loss: 0.00370 | Acc: 0.999 | Val ACC: 0.890\n",
      "Epoch 097: | Loss: 0.00259 | Acc: 0.999 | Val ACC: 0.890\n",
      "Epoch 098: | Loss: 0.00374 | Acc: 0.999 | Val ACC: 0.890\n",
      "Epoch 099: | Loss: 0.00259 | Acc: 0.999 | Val ACC: 0.890\n"
     ]
    }
   ],
   "source": [
    "from Model import make_models\n",
    "import torch \n",
    "from Courier import SyncLocalCourier\n",
    "from VFLDataUtils import SimpleNumpyDataLoader\n",
    "from Client import SyncFNNClient\n",
    "from Strategy import SyncConcatStrategy\n",
    "from Server import SyncFNNServer\n",
    "torch.manual_seed(0)\n",
    "EMB_DIM = 128\n",
    "baselines_no_fs = {}\n",
    "for client_num in range(1, 6):\n",
    "    client_id_list = list(range(client_num))\n",
    "    courier = SyncLocalCourier(client_id_list)\n",
    "    loader = SimpleNumpyDataLoader(\n",
    "        clients_id_list=client_id_list,\n",
    "        data_source=(basehock_X, basehock_y)\n",
    "    )\n",
    "    loader_dict, input_dims = loader.distribute()\n",
    "    models, top_model = make_models(input_dims)\n",
    "    # for model in models: print(model)\n",
    "    # print(top_model)\n",
    "    clients = []\n",
    "    for i, id in enumerate(client_id_list):\n",
    "        client = SyncFNNClient(\n",
    "            id=id,\n",
    "            model= models[i],\n",
    "            courier=courier,\n",
    "            train_loader=loader_dict[id]['train_loader'],\n",
    "            test_loader=loader_dict[id]['test_loader'],\n",
    "            config_dir='simple_config.ini')\n",
    "        clients.append(client)\n",
    "    strategy = SyncConcatStrategy(courier=courier, clients=clients)\n",
    "    server = SyncFNNServer(\n",
    "        strategy=strategy,\n",
    "        courier=courier,\n",
    "        top_model=top_model,\n",
    "        emb_model=models[-1],\n",
    "        train_loader=loader_dict['server']['train_loader'],\n",
    "        test_loader=loader_dict['server']['test_loader'],\n",
    "        config_dir='simple_config.ini')\n",
    "    \n",
    "    print('Training Starts')\n",
    "    print(f'Number of Clients: {client_num}')\n",
    "    print('-'*89)\n",
    "    for epoch in range(100):\n",
    "        server.fit(epoch)\n",
    "    history = server.get_history()\n",
    "    baselines_no_fs[client_num] = history    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STG on Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: Feature Index 0-2430\n",
      "Server : Feature Index 2431-4861\n",
      "Training Starts\n",
      "Number of Clients: 1\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: | Loss: 0.43087 | Acc: 0.784 | Val ACC: 0.947 | Features Left: 1411\n",
      "Epoch 001: | Loss: 0.06318 | Acc: 0.981 | Val ACC: 0.965 | Features Left: 1585\n",
      "Epoch 002: | Loss: 0.03729 | Acc: 0.992 | Val ACC: 0.932 | Features Left: 1614\n",
      "Epoch 003: | Loss: 0.01573 | Acc: 0.997 | Val ACC: 0.952 | Features Left: 1621\n",
      "Epoch 004: | Loss: 0.00066 | Acc: 1.000 | Val ACC: 0.952 | Features Left: 1616\n",
      "Epoch 005: | Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 1599\n",
      "Epoch 006: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.952 | Features Left: 1578\n",
      "Epoch 007: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 1560\n",
      "Epoch 008: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.950 | Features Left: 1549\n",
      "Epoch 009: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.950 | Features Left: 1534\n",
      "Epoch 010: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.947 | Features Left: 1518\n",
      "Epoch 011: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.947 | Features Left: 1506\n",
      "Epoch 012: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.947 | Features Left: 1496\n",
      "Epoch 013: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.945 | Features Left: 1484\n",
      "Epoch 014: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1474\n",
      "Epoch 015: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1466\n",
      "Epoch 016: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1449\n",
      "Epoch 017: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1442\n",
      "Epoch 018: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1432\n",
      "Epoch 019: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1419\n",
      "Epoch 020: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1414\n",
      "Epoch 021: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1403\n",
      "Epoch 022: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1398\n",
      "Epoch 023: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1389\n",
      "Epoch 024: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1387\n",
      "Epoch 025: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1381\n",
      "Epoch 026: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.937 | Features Left: 1374\n",
      "Epoch 027: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 1366\n",
      "Epoch 028: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1363\n",
      "Epoch 029: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1360\n",
      "Epoch 030: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1359\n",
      "Epoch 031: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1355\n",
      "Epoch 032: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.942 | Features Left: 1349\n",
      "Epoch 033: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.937 | Features Left: 1345\n",
      "Epoch 034: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.937 | Features Left: 1342\n",
      "Epoch 035: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.937 | Features Left: 1342\n",
      "Epoch 036: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.937 | Features Left: 1339\n",
      "Epoch 037: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.937 | Features Left: 1336\n",
      "Epoch 038: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 1331\n",
      "Epoch 039: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 1324\n",
      "Epoch 040: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 1320\n",
      "Epoch 041: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 1318\n",
      "Epoch 042: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 1314\n",
      "Epoch 043: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 1310\n",
      "Epoch 044: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.937 | Features Left: 1307\n",
      "Epoch 045: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.937 | Features Left: 1305\n",
      "Epoch 046: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.937 | Features Left: 1301\n",
      "Epoch 047: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.937 | Features Left: 1300\n",
      "Epoch 048: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.937 | Features Left: 1298\n",
      "Epoch 049: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1295\n",
      "Epoch 050: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1294\n",
      "Epoch 051: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1294\n",
      "Epoch 052: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1294\n",
      "Epoch 053: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1292\n",
      "Epoch 054: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1291\n",
      "Epoch 055: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1289\n",
      "Epoch 056: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1285\n",
      "Epoch 057: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1283\n",
      "Epoch 058: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1279\n",
      "Epoch 059: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1278\n",
      "Epoch 060: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.925 | Features Left: 1275\n",
      "Epoch 061: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.922 | Features Left: 1273\n",
      "Epoch 062: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.922 | Features Left: 1269\n",
      "Epoch 063: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.925 | Features Left: 1267\n",
      "Epoch 064: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.922 | Features Left: 1264\n",
      "Epoch 065: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.922 | Features Left: 1263\n",
      "Epoch 066: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.922 | Features Left: 1259\n",
      "Epoch 067: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.925 | Features Left: 1259\n",
      "Epoch 068: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1257\n",
      "Epoch 069: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1257\n",
      "Epoch 070: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1256\n",
      "Epoch 071: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1256\n",
      "Epoch 072: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1256\n",
      "Epoch 073: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1255\n",
      "Epoch 074: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1253\n",
      "Epoch 075: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1251\n",
      "Epoch 076: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1250\n",
      "Epoch 077: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1249\n",
      "Epoch 078: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1249\n",
      "Epoch 079: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1249\n",
      "Epoch 080: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1249\n",
      "Epoch 081: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1249\n",
      "Epoch 082: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1249\n",
      "Epoch 083: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1247\n",
      "Epoch 084: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1247\n",
      "Epoch 085: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1247\n",
      "Epoch 086: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1245\n",
      "Epoch 087: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1243\n",
      "Epoch 088: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1242\n",
      "Epoch 089: | Loss: 0.24233 | Acc: 0.987 | Val ACC: 0.895 | Features Left: 1251\n",
      "Epoch 090: | Loss: 1.41506 | Acc: 0.819 | Val ACC: 0.872 | Features Left: 1265\n",
      "Epoch 091: | Loss: 1.45119 | Acc: 0.894 | Val ACC: 0.912 | Features Left: 1278\n",
      "Epoch 092: | Loss: 1.45990 | Acc: 0.968 | Val ACC: 0.927 | Features Left: 1300\n",
      "Epoch 093: | Loss: 0.82276 | Acc: 0.966 | Val ACC: 0.922 | Features Left: 1311\n",
      "Epoch 094: | Loss: 1.24479 | Acc: 0.981 | Val ACC: 0.925 | Features Left: 1325\n",
      "Epoch 095: | Loss: 1.14940 | Acc: 0.983 | Val ACC: 0.927 | Features Left: 1326\n",
      "Epoch 096: | Loss: 1.13030 | Acc: 0.986 | Val ACC: 0.922 | Features Left: 1328\n",
      "Epoch 097: | Loss: 1.08504 | Acc: 0.987 | Val ACC: 0.925 | Features Left: 1329\n",
      "Epoch 098: | Loss: 0.80457 | Acc: 0.987 | Val ACC: 0.920 | Features Left: 1331\n",
      "Epoch 099: | Loss: 0.39807 | Acc: 0.990 | Val ACC: 0.922 | Features Left: 1326\n",
      "Client 0: Feature Index 0-1620\n",
      "Client 1: Feature Index 1621-3241\n",
      "Server : Feature Index 3242-4861\n",
      "Training Starts\n",
      "Number of Clients: 2\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: | Loss: 0.52177 | Acc: 0.721 | Val ACC: 0.885 | Features Left: 1768\n",
      "Epoch 001: | Loss: 0.12438 | Acc: 0.963 | Val ACC: 0.915 | Features Left: 1974\n",
      "Epoch 002: | Loss: 0.04935 | Acc: 0.983 | Val ACC: 0.927 | Features Left: 2039\n",
      "Epoch 003: | Loss: 0.01065 | Acc: 0.995 | Val ACC: 0.930 | Features Left: 2055\n",
      "Epoch 004: | Loss: 0.00147 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 2052\n",
      "Epoch 005: | Loss: 0.00009 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 2039\n",
      "Epoch 006: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 2020\n",
      "Epoch 007: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.925 | Features Left: 1997\n",
      "Epoch 008: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.925 | Features Left: 1975\n",
      "Epoch 009: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.922 | Features Left: 1957\n",
      "Epoch 010: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.922 | Features Left: 1941\n",
      "Epoch 011: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.922 | Features Left: 1936\n",
      "Epoch 012: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.920 | Features Left: 1912\n",
      "Epoch 013: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.920 | Features Left: 1904\n",
      "Epoch 014: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.920 | Features Left: 1895\n",
      "Epoch 015: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.917 | Features Left: 1884\n",
      "Epoch 016: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.915 | Features Left: 1879\n",
      "Epoch 017: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.917 | Features Left: 1869\n",
      "Epoch 018: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.917 | Features Left: 1861\n",
      "Epoch 019: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.920 | Features Left: 1854\n",
      "Epoch 020: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.920 | Features Left: 1850\n",
      "Epoch 021: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.920 | Features Left: 1843\n",
      "Epoch 022: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.920 | Features Left: 1829\n",
      "Epoch 023: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.920 | Features Left: 1822\n",
      "Epoch 024: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.920 | Features Left: 1818\n",
      "Epoch 025: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.920 | Features Left: 1810\n",
      "Epoch 026: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.920 | Features Left: 1805\n",
      "Epoch 027: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.920 | Features Left: 1796\n",
      "Epoch 028: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.917 | Features Left: 1793\n",
      "Epoch 029: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.915 | Features Left: 1793\n",
      "Epoch 030: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.915 | Features Left: 1789\n",
      "Epoch 031: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.915 | Features Left: 1782\n",
      "Epoch 032: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 1780\n",
      "Epoch 033: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 1773\n",
      "Epoch 034: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 1769\n",
      "Epoch 035: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 1761\n",
      "Epoch 036: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 1758\n",
      "Epoch 037: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1757\n",
      "Epoch 038: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1754\n",
      "Epoch 039: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1750\n",
      "Epoch 040: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1747\n",
      "Epoch 041: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1740\n",
      "Epoch 042: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1739\n",
      "Epoch 043: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1735\n",
      "Epoch 044: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1733\n",
      "Epoch 045: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1730\n",
      "Epoch 046: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 1728\n",
      "Epoch 047: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1725\n",
      "Epoch 048: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 1725\n",
      "Epoch 049: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1723\n",
      "Epoch 050: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 1722\n",
      "Epoch 051: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 1720\n",
      "Epoch 052: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 1715\n",
      "Epoch 053: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 1711\n",
      "Epoch 054: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 1711\n",
      "Epoch 055: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 1711\n",
      "Epoch 056: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1711\n",
      "Epoch 057: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1709\n",
      "Epoch 058: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1709\n",
      "Epoch 059: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1709\n",
      "Epoch 060: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 1709\n",
      "Epoch 061: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 1708\n",
      "Epoch 062: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 1707\n",
      "Epoch 063: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 1705\n",
      "Epoch 064: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 1704\n",
      "Epoch 065: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 1704\n",
      "Epoch 066: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.915 | Features Left: 1703\n",
      "Epoch 067: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 1702\n",
      "Epoch 068: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 1702\n",
      "Epoch 069: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.917 | Features Left: 1700\n",
      "Epoch 070: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.920 | Features Left: 1699\n",
      "Epoch 071: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.917 | Features Left: 1697\n",
      "Epoch 072: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.915 | Features Left: 1695\n",
      "Epoch 073: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.915 | Features Left: 1694\n",
      "Epoch 074: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.915 | Features Left: 1693\n",
      "Epoch 075: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.917 | Features Left: 1691\n",
      "Epoch 076: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.917 | Features Left: 1690\n",
      "Epoch 077: | Loss: 0.86374 | Acc: 0.929 | Val ACC: 0.820 | Features Left: 1683\n",
      "Epoch 078: | Loss: 0.98158 | Acc: 0.815 | Val ACC: 0.897 | Features Left: 1725\n",
      "Epoch 079: | Loss: 0.74824 | Acc: 0.838 | Val ACC: 0.877 | Features Left: 1755\n",
      "Epoch 080: | Loss: 0.22994 | Acc: 0.963 | Val ACC: 0.905 | Features Left: 1774\n",
      "Epoch 081: | Loss: 0.32575 | Acc: 0.970 | Val ACC: 0.905 | Features Left: 1778\n",
      "Epoch 082: | Loss: 0.34801 | Acc: 0.978 | Val ACC: 0.895 | Features Left: 1784\n",
      "Epoch 083: | Loss: 0.32027 | Acc: 0.990 | Val ACC: 0.887 | Features Left: 1789\n",
      "Epoch 084: | Loss: 0.31710 | Acc: 0.993 | Val ACC: 0.897 | Features Left: 1790\n",
      "Epoch 085: | Loss: 0.36903 | Acc: 0.995 | Val ACC: 0.900 | Features Left: 1791\n",
      "Epoch 086: | Loss: 0.36752 | Acc: 0.995 | Val ACC: 0.907 | Features Left: 1791\n",
      "Epoch 087: | Loss: 0.36571 | Acc: 0.995 | Val ACC: 0.910 | Features Left: 1791\n",
      "Epoch 088: | Loss: 0.36433 | Acc: 0.995 | Val ACC: 0.907 | Features Left: 1791\n",
      "Epoch 089: | Loss: 0.36380 | Acc: 0.995 | Val ACC: 0.905 | Features Left: 1791\n",
      "Epoch 090: | Loss: 0.36332 | Acc: 0.996 | Val ACC: 0.905 | Features Left: 1792\n",
      "Epoch 091: | Loss: 0.36300 | Acc: 0.996 | Val ACC: 0.902 | Features Left: 1792\n",
      "Epoch 092: | Loss: 0.36275 | Acc: 0.995 | Val ACC: 0.902 | Features Left: 1792\n",
      "Epoch 093: | Loss: 0.36253 | Acc: 0.995 | Val ACC: 0.902 | Features Left: 1792\n",
      "Epoch 094: | Loss: 0.36235 | Acc: 0.995 | Val ACC: 0.902 | Features Left: 1791\n",
      "Epoch 095: | Loss: 0.36232 | Acc: 0.995 | Val ACC: 0.902 | Features Left: 1791\n",
      "Epoch 096: | Loss: 0.36218 | Acc: 0.995 | Val ACC: 0.902 | Features Left: 1790\n",
      "Epoch 097: | Loss: 0.36214 | Acc: 0.995 | Val ACC: 0.900 | Features Left: 1790\n",
      "Epoch 098: | Loss: 0.36210 | Acc: 0.995 | Val ACC: 0.900 | Features Left: 1790\n",
      "Epoch 099: | Loss: 0.36207 | Acc: 0.995 | Val ACC: 0.900 | Features Left: 1790\n",
      "Client 0: Feature Index 0-1215\n",
      "Client 1: Feature Index 1216-2431\n",
      "Client 2: Feature Index 2432-3646\n",
      "Server : Feature Index 3647-4861\n",
      "Training Starts\n",
      "Number of Clients: 3\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: | Loss: 0.55976 | Acc: 0.715 | Val ACC: 0.885 | Features Left: 1929\n",
      "Epoch 001: | Loss: 0.21417 | Acc: 0.943 | Val ACC: 0.925 | Features Left: 2071\n",
      "Epoch 002: | Loss: 0.13026 | Acc: 0.972 | Val ACC: 0.915 | Features Left: 2145\n",
      "Epoch 003: | Loss: 0.11983 | Acc: 0.977 | Val ACC: 0.910 | Features Left: 2173\n",
      "Epoch 004: | Loss: 0.07601 | Acc: 0.993 | Val ACC: 0.907 | Features Left: 2204\n",
      "Epoch 005: | Loss: 0.06354 | Acc: 0.998 | Val ACC: 0.905 | Features Left: 2210\n",
      "Epoch 006: | Loss: 0.06044 | Acc: 0.999 | Val ACC: 0.905 | Features Left: 2194\n",
      "Epoch 007: | Loss: 0.06021 | Acc: 0.999 | Val ACC: 0.895 | Features Left: 2182\n",
      "Epoch 008: | Loss: 0.06013 | Acc: 0.999 | Val ACC: 0.897 | Features Left: 2171\n",
      "Epoch 009: | Loss: 0.06011 | Acc: 0.999 | Val ACC: 0.897 | Features Left: 2160\n",
      "Epoch 010: | Loss: 0.06011 | Acc: 0.999 | Val ACC: 0.897 | Features Left: 2151\n",
      "Epoch 011: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.897 | Features Left: 2140\n",
      "Epoch 012: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.897 | Features Left: 2130\n",
      "Epoch 013: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.897 | Features Left: 2122\n",
      "Epoch 014: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.897 | Features Left: 2117\n",
      "Epoch 015: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.897 | Features Left: 2110\n",
      "Epoch 016: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.897 | Features Left: 2101\n",
      "Epoch 017: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.897 | Features Left: 2098\n",
      "Epoch 018: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.895 | Features Left: 2094\n",
      "Epoch 019: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.895 | Features Left: 2087\n",
      "Epoch 020: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.895 | Features Left: 2080\n",
      "Epoch 021: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.892 | Features Left: 2073\n",
      "Epoch 022: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.892 | Features Left: 2069\n",
      "Epoch 023: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.892 | Features Left: 2065\n",
      "Epoch 024: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.890 | Features Left: 2060\n",
      "Epoch 025: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.890 | Features Left: 2050\n",
      "Epoch 026: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.887 | Features Left: 2045\n",
      "Epoch 027: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.887 | Features Left: 2038\n",
      "Epoch 028: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.887 | Features Left: 2031\n",
      "Epoch 029: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.887 | Features Left: 2020\n",
      "Epoch 030: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.887 | Features Left: 2017\n",
      "Epoch 031: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.887 | Features Left: 2015\n",
      "Epoch 032: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.887 | Features Left: 2008\n",
      "Epoch 033: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.885 | Features Left: 2003\n",
      "Epoch 034: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.885 | Features Left: 2002\n",
      "Epoch 035: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.885 | Features Left: 1997\n",
      "Epoch 036: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.885 | Features Left: 1992\n",
      "Epoch 037: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.885 | Features Left: 1984\n",
      "Epoch 038: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.885 | Features Left: 1980\n",
      "Epoch 039: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.885 | Features Left: 1976\n",
      "Epoch 040: | Loss: 0.06010 | Acc: 0.999 | Val ACC: 0.885 | Features Left: 1972\n",
      "Epoch 041: | Loss: 0.07780 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 1973\n",
      "Epoch 042: | Loss: 1.02625 | Acc: 0.884 | Val ACC: 0.857 | Features Left: 1997\n",
      "Epoch 043: | Loss: 0.20418 | Acc: 0.917 | Val ACC: 0.895 | Features Left: 2027\n",
      "Epoch 044: | Loss: 0.07973 | Acc: 0.976 | Val ACC: 0.900 | Features Left: 2056\n",
      "Epoch 045: | Loss: 0.04533 | Acc: 0.990 | Val ACC: 0.905 | Features Left: 2073\n",
      "Epoch 046: | Loss: 0.03267 | Acc: 0.988 | Val ACC: 0.912 | Features Left: 2077\n",
      "Epoch 047: | Loss: 0.08681 | Acc: 0.992 | Val ACC: 0.902 | Features Left: 2086\n",
      "Epoch 048: | Loss: 0.01460 | Acc: 0.995 | Val ACC: 0.912 | Features Left: 2089\n",
      "Epoch 049: | Loss: 0.00252 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2087\n",
      "Epoch 050: | Loss: 0.00068 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2084\n",
      "Epoch 051: | Loss: 0.00023 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2084\n",
      "Epoch 052: | Loss: 0.00008 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2084\n",
      "Epoch 053: | Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2082\n",
      "Epoch 054: | Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2082\n",
      "Epoch 055: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 2080\n",
      "Epoch 056: | Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 2080\n",
      "Epoch 057: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 2076\n",
      "Epoch 058: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 2073\n",
      "Epoch 059: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 2073\n",
      "Epoch 060: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 2073\n",
      "Epoch 061: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2070\n",
      "Epoch 062: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2067\n",
      "Epoch 063: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2067\n",
      "Epoch 064: | Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2067\n",
      "Epoch 065: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2066\n",
      "Epoch 066: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2066\n",
      "Epoch 067: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2065\n",
      "Epoch 068: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2065\n",
      "Epoch 069: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2065\n",
      "Epoch 070: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2062\n",
      "Epoch 071: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2060\n",
      "Epoch 072: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2059\n",
      "Epoch 073: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2058\n",
      "Epoch 074: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2054\n",
      "Epoch 075: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2050\n",
      "Epoch 076: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 2049\n",
      "Epoch 077: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2049\n",
      "Epoch 078: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2047\n",
      "Epoch 079: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2047\n",
      "Epoch 080: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2046\n",
      "Epoch 081: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 2046\n",
      "Epoch 082: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 2044\n",
      "Epoch 083: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2042\n",
      "Epoch 084: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2040\n",
      "Epoch 085: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2038\n",
      "Epoch 086: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2036\n",
      "Epoch 087: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2035\n",
      "Epoch 088: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2031\n",
      "Epoch 089: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2028\n",
      "Epoch 090: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2025\n",
      "Epoch 091: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 2025\n",
      "Epoch 092: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 2025\n",
      "Epoch 093: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 2022\n",
      "Epoch 094: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 2021\n",
      "Epoch 095: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 2021\n",
      "Epoch 096: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 2020\n",
      "Epoch 097: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2017\n",
      "Epoch 098: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2014\n",
      "Epoch 099: | Loss: 0.00000 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2014\n",
      "Client 0: Feature Index 0-972\n",
      "Client 1: Feature Index 973-1945\n",
      "Client 2: Feature Index 1946-2917\n",
      "Client 3: Feature Index 2918-3889\n",
      "Server : Feature Index 3890-4861\n",
      "Training Starts\n",
      "Number of Clients: 4\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: | Loss: 0.60410 | Acc: 0.674 | Val ACC: 0.835 | Features Left: 2026\n",
      "Epoch 001: | Loss: 0.22893 | Acc: 0.912 | Val ACC: 0.905 | Features Left: 2144\n",
      "Epoch 002: | Loss: 0.11331 | Acc: 0.957 | Val ACC: 0.890 | Features Left: 2209\n",
      "Epoch 003: | Loss: 0.08937 | Acc: 0.958 | Val ACC: 0.890 | Features Left: 2243\n",
      "Epoch 004: | Loss: 0.04187 | Acc: 0.986 | Val ACC: 0.895 | Features Left: 2266\n",
      "Epoch 005: | Loss: 0.02012 | Acc: 0.992 | Val ACC: 0.910 | Features Left: 2269\n",
      "Epoch 006: | Loss: 0.02143 | Acc: 0.994 | Val ACC: 0.907 | Features Left: 2269\n",
      "Epoch 007: | Loss: 0.01223 | Acc: 0.996 | Val ACC: 0.900 | Features Left: 2262\n",
      "Epoch 008: | Loss: 0.01256 | Acc: 0.996 | Val ACC: 0.890 | Features Left: 2265\n",
      "Epoch 009: | Loss: 0.00644 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2259\n",
      "Epoch 010: | Loss: 0.00635 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2257\n",
      "Epoch 011: | Loss: 0.00441 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2249\n",
      "Epoch 012: | Loss: 0.00437 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2244\n",
      "Epoch 013: | Loss: 0.00397 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2239\n",
      "Epoch 014: | Loss: 0.00357 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2235\n",
      "Epoch 015: | Loss: 0.00336 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2225\n",
      "Epoch 016: | Loss: 0.00324 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2222\n",
      "Epoch 017: | Loss: 0.00311 | Acc: 0.998 | Val ACC: 0.900 | Features Left: 2219\n",
      "Epoch 018: | Loss: 0.00309 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2208\n",
      "Epoch 019: | Loss: 0.00284 | Acc: 0.999 | Val ACC: 0.892 | Features Left: 2202\n",
      "Epoch 020: | Loss: 0.00276 | Acc: 0.999 | Val ACC: 0.892 | Features Left: 2196\n",
      "Epoch 021: | Loss: 0.00267 | Acc: 0.999 | Val ACC: 0.890 | Features Left: 2192\n",
      "Epoch 022: | Loss: 0.00274 | Acc: 0.999 | Val ACC: 0.890 | Features Left: 2186\n",
      "Epoch 023: | Loss: 0.00213 | Acc: 0.999 | Val ACC: 0.890 | Features Left: 2180\n",
      "Epoch 024: | Loss: 0.00293 | Acc: 0.998 | Val ACC: 0.887 | Features Left: 2177\n",
      "Epoch 025: | Loss: 0.00189 | Acc: 0.999 | Val ACC: 0.885 | Features Left: 2170\n",
      "Epoch 026: | Loss: 0.00290 | Acc: 0.999 | Val ACC: 0.885 | Features Left: 2163\n",
      "Epoch 027: | Loss: 0.00174 | Acc: 0.999 | Val ACC: 0.882 | Features Left: 2160\n",
      "Epoch 028: | Loss: 0.00187 | Acc: 0.999 | Val ACC: 0.885 | Features Left: 2158\n",
      "Epoch 029: | Loss: 0.00157 | Acc: 0.999 | Val ACC: 0.885 | Features Left: 2156\n",
      "Epoch 030: | Loss: 0.00207 | Acc: 0.999 | Val ACC: 0.880 | Features Left: 2154\n",
      "Epoch 031: | Loss: 0.00158 | Acc: 0.999 | Val ACC: 0.877 | Features Left: 2152\n",
      "Epoch 032: | Loss: 0.00204 | Acc: 0.999 | Val ACC: 0.875 | Features Left: 2151\n",
      "Epoch 033: | Loss: 0.00155 | Acc: 0.999 | Val ACC: 0.875 | Features Left: 2148\n",
      "Epoch 034: | Loss: 0.00173 | Acc: 0.999 | Val ACC: 0.875 | Features Left: 2145\n",
      "Epoch 035: | Loss: 0.00156 | Acc: 0.999 | Val ACC: 0.875 | Features Left: 2143\n",
      "Epoch 036: | Loss: 0.00160 | Acc: 0.999 | Val ACC: 0.875 | Features Left: 2139\n",
      "Epoch 037: | Loss: 0.00140 | Acc: 0.999 | Val ACC: 0.875 | Features Left: 2136\n",
      "Epoch 038: | Loss: 0.00169 | Acc: 0.999 | Val ACC: 0.875 | Features Left: 2129\n",
      "Epoch 039: | Loss: 0.00138 | Acc: 0.999 | Val ACC: 0.870 | Features Left: 2128\n",
      "Epoch 040: | Loss: 0.00141 | Acc: 0.999 | Val ACC: 0.872 | Features Left: 2125\n",
      "Epoch 041: | Loss: 0.00147 | Acc: 0.999 | Val ACC: 0.872 | Features Left: 2125\n",
      "Epoch 042: | Loss: 0.00133 | Acc: 0.999 | Val ACC: 0.872 | Features Left: 2121\n",
      "Epoch 043: | Loss: 0.00144 | Acc: 0.999 | Val ACC: 0.872 | Features Left: 2116\n",
      "Epoch 044: | Loss: 0.00117 | Acc: 0.999 | Val ACC: 0.870 | Features Left: 2111\n",
      "Epoch 045: | Loss: 0.00152 | Acc: 0.999 | Val ACC: 0.870 | Features Left: 2108\n",
      "Epoch 046: | Loss: 0.00113 | Acc: 1.000 | Val ACC: 0.870 | Features Left: 2104\n",
      "Epoch 047: | Loss: 0.00186 | Acc: 0.999 | Val ACC: 0.872 | Features Left: 2100\n",
      "Epoch 048: | Loss: 0.00104 | Acc: 0.999 | Val ACC: 0.870 | Features Left: 2099\n",
      "Epoch 049: | Loss: 0.00125 | Acc: 0.999 | Val ACC: 0.867 | Features Left: 2095\n",
      "Epoch 050: | Loss: 0.00127 | Acc: 0.999 | Val ACC: 0.870 | Features Left: 2089\n",
      "Epoch 051: | Loss: 0.00116 | Acc: 0.999 | Val ACC: 0.867 | Features Left: 2087\n",
      "Epoch 052: | Loss: 0.00119 | Acc: 0.999 | Val ACC: 0.867 | Features Left: 2083\n",
      "Epoch 053: | Loss: 0.00133 | Acc: 0.999 | Val ACC: 0.867 | Features Left: 2080\n",
      "Epoch 054: | Loss: 0.02048 | Acc: 0.995 | Val ACC: 0.872 | Features Left: 2080\n",
      "Epoch 055: | Loss: 0.05687 | Acc: 0.981 | Val ACC: 0.870 | Features Left: 2114\n",
      "Epoch 056: | Loss: 0.06242 | Acc: 0.982 | Val ACC: 0.847 | Features Left: 2163\n",
      "Epoch 057: | Loss: 0.02900 | Acc: 0.988 | Val ACC: 0.885 | Features Left: 2191\n",
      "Epoch 058: | Loss: 0.15683 | Acc: 0.985 | Val ACC: 0.852 | Features Left: 2201\n",
      "Epoch 059: | Loss: 0.24658 | Acc: 0.968 | Val ACC: 0.880 | Features Left: 2229\n",
      "Epoch 060: | Loss: 2.68798 | Acc: 0.946 | Val ACC: 0.872 | Features Left: 2227\n",
      "Epoch 061: | Loss: 0.84162 | Acc: 0.979 | Val ACC: 0.870 | Features Left: 2226\n",
      "Epoch 062: | Loss: 0.88776 | Acc: 0.974 | Val ACC: 0.870 | Features Left: 2226\n",
      "Epoch 063: | Loss: 0.75853 | Acc: 0.964 | Val ACC: 0.850 | Features Left: 2238\n",
      "Epoch 064: | Loss: 0.71396 | Acc: 0.978 | Val ACC: 0.850 | Features Left: 2239\n",
      "Epoch 065: | Loss: 0.66931 | Acc: 0.978 | Val ACC: 0.865 | Features Left: 2250\n",
      "Epoch 066: | Loss: 0.63482 | Acc: 0.977 | Val ACC: 0.865 | Features Left: 2251\n",
      "Epoch 067: | Loss: 0.59825 | Acc: 0.988 | Val ACC: 0.865 | Features Left: 2255\n",
      "Epoch 068: | Loss: 0.66733 | Acc: 0.984 | Val ACC: 0.867 | Features Left: 2259\n",
      "Epoch 069: | Loss: 0.69051 | Acc: 0.989 | Val ACC: 0.867 | Features Left: 2261\n",
      "Epoch 070: | Loss: 0.49931 | Acc: 0.988 | Val ACC: 0.877 | Features Left: 2261\n",
      "Epoch 071: | Loss: 0.55599 | Acc: 0.989 | Val ACC: 0.872 | Features Left: 2262\n",
      "Epoch 072: | Loss: 0.55135 | Acc: 0.990 | Val ACC: 0.872 | Features Left: 2261\n",
      "Epoch 073: | Loss: 0.54877 | Acc: 0.991 | Val ACC: 0.875 | Features Left: 2261\n",
      "Epoch 074: | Loss: 0.54764 | Acc: 0.991 | Val ACC: 0.872 | Features Left: 2260\n",
      "Epoch 075: | Loss: 0.54761 | Acc: 0.992 | Val ACC: 0.882 | Features Left: 2258\n",
      "Epoch 076: | Loss: 0.54504 | Acc: 0.993 | Val ACC: 0.880 | Features Left: 2258\n",
      "Epoch 077: | Loss: 0.54612 | Acc: 0.993 | Val ACC: 0.877 | Features Left: 2257\n",
      "Epoch 078: | Loss: 0.54442 | Acc: 0.993 | Val ACC: 0.877 | Features Left: 2257\n",
      "Epoch 079: | Loss: 0.54536 | Acc: 0.993 | Val ACC: 0.880 | Features Left: 2257\n",
      "Epoch 080: | Loss: 0.54423 | Acc: 0.993 | Val ACC: 0.880 | Features Left: 2254\n",
      "Epoch 081: | Loss: 0.54463 | Acc: 0.993 | Val ACC: 0.880 | Features Left: 2253\n",
      "Epoch 082: | Loss: 0.54430 | Acc: 0.993 | Val ACC: 0.880 | Features Left: 2250\n",
      "Epoch 083: | Loss: 0.54419 | Acc: 0.993 | Val ACC: 0.880 | Features Left: 2248\n",
      "Epoch 084: | Loss: 0.54405 | Acc: 0.993 | Val ACC: 0.880 | Features Left: 2248\n",
      "Epoch 085: | Loss: 0.54404 | Acc: 0.994 | Val ACC: 0.880 | Features Left: 2247\n",
      "Epoch 086: | Loss: 0.54406 | Acc: 0.994 | Val ACC: 0.880 | Features Left: 2244\n",
      "Epoch 087: | Loss: 0.54364 | Acc: 0.994 | Val ACC: 0.880 | Features Left: 2243\n",
      "Epoch 088: | Loss: 0.54364 | Acc: 0.994 | Val ACC: 0.880 | Features Left: 2243\n",
      "Epoch 089: | Loss: 0.54323 | Acc: 0.994 | Val ACC: 0.880 | Features Left: 2243\n",
      "Epoch 090: | Loss: 0.54329 | Acc: 0.994 | Val ACC: 0.880 | Features Left: 2243\n",
      "Epoch 091: | Loss: 0.54300 | Acc: 0.994 | Val ACC: 0.877 | Features Left: 2242\n",
      "Epoch 092: | Loss: 0.54334 | Acc: 0.994 | Val ACC: 0.880 | Features Left: 2241\n",
      "Epoch 093: | Loss: 0.54305 | Acc: 0.994 | Val ACC: 0.880 | Features Left: 2239\n",
      "Epoch 094: | Loss: 0.54243 | Acc: 0.994 | Val ACC: 0.880 | Features Left: 2238\n",
      "Epoch 095: | Loss: 0.54468 | Acc: 0.993 | Val ACC: 0.877 | Features Left: 2238\n",
      "Epoch 096: | Loss: 0.54273 | Acc: 0.994 | Val ACC: 0.875 | Features Left: 2236\n",
      "Epoch 097: | Loss: 0.54319 | Acc: 0.994 | Val ACC: 0.880 | Features Left: 2236\n",
      "Epoch 098: | Loss: 0.54227 | Acc: 0.994 | Val ACC: 0.875 | Features Left: 2234\n",
      "Epoch 099: | Loss: 0.54368 | Acc: 0.993 | Val ACC: 0.877 | Features Left: 2233\n",
      "Client 0: Feature Index 0-810\n",
      "Client 1: Feature Index 811-1621\n",
      "Client 2: Feature Index 1622-2431\n",
      "Client 3: Feature Index 2432-3241\n",
      "Client 4: Feature Index 3242-4051\n",
      "Server : Feature Index 4052-4861\n",
      "Training Starts\n",
      "Number of Clients: 5\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: | Loss: 0.68451 | Acc: 0.630 | Val ACC: 0.789 | Features Left: 2145\n",
      "Epoch 001: | Loss: 0.30697 | Acc: 0.895 | Val ACC: 0.870 | Features Left: 2251\n",
      "Epoch 002: | Loss: 0.16903 | Acc: 0.947 | Val ACC: 0.860 | Features Left: 2312\n",
      "Epoch 003: | Loss: 0.16182 | Acc: 0.943 | Val ACC: 0.877 | Features Left: 2337\n",
      "Epoch 004: | Loss: 0.16984 | Acc: 0.963 | Val ACC: 0.845 | Features Left: 2361\n",
      "Epoch 005: | Loss: 0.13755 | Acc: 0.972 | Val ACC: 0.887 | Features Left: 2382\n",
      "Epoch 006: | Loss: 0.09691 | Acc: 0.985 | Val ACC: 0.895 | Features Left: 2389\n",
      "Epoch 007: | Loss: 0.08110 | Acc: 0.991 | Val ACC: 0.887 | Features Left: 2387\n",
      "Epoch 008: | Loss: 0.07509 | Acc: 0.995 | Val ACC: 0.902 | Features Left: 2387\n",
      "Epoch 009: | Loss: 0.06805 | Acc: 0.997 | Val ACC: 0.902 | Features Left: 2384\n",
      "Epoch 010: | Loss: 0.06928 | Acc: 0.997 | Val ACC: 0.902 | Features Left: 2378\n",
      "Epoch 011: | Loss: 0.06666 | Acc: 0.997 | Val ACC: 0.902 | Features Left: 2374\n",
      "Epoch 012: | Loss: 0.06611 | Acc: 0.998 | Val ACC: 0.907 | Features Left: 2367\n",
      "Epoch 013: | Loss: 0.07174 | Acc: 0.996 | Val ACC: 0.890 | Features Left: 2363\n",
      "Epoch 014: | Loss: 0.13784 | Acc: 0.995 | Val ACC: 0.887 | Features Left: 2359\n",
      "Epoch 015: | Loss: 0.10812 | Acc: 0.988 | Val ACC: 0.890 | Features Left: 2364\n",
      "Epoch 016: | Loss: 0.09728 | Acc: 0.986 | Val ACC: 0.885 | Features Left: 2393\n",
      "Epoch 017: | Loss: 0.09001 | Acc: 0.988 | Val ACC: 0.890 | Features Left: 2401\n",
      "Epoch 018: | Loss: 0.07470 | Acc: 0.995 | Val ACC: 0.882 | Features Left: 2404\n",
      "Epoch 019: | Loss: 0.07054 | Acc: 0.996 | Val ACC: 0.895 | Features Left: 2399\n",
      "Epoch 020: | Loss: 0.06619 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2395\n",
      "Epoch 021: | Loss: 0.06615 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2393\n",
      "Epoch 022: | Loss: 0.06603 | Acc: 0.997 | Val ACC: 0.890 | Features Left: 2391\n",
      "Epoch 023: | Loss: 0.06528 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2389\n",
      "Epoch 024: | Loss: 0.06541 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2387\n",
      "Epoch 025: | Loss: 0.06460 | Acc: 0.998 | Val ACC: 0.887 | Features Left: 2385\n",
      "Epoch 026: | Loss: 0.06456 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2383\n",
      "Epoch 027: | Loss: 0.06401 | Acc: 0.998 | Val ACC: 0.885 | Features Left: 2382\n",
      "Epoch 028: | Loss: 0.06401 | Acc: 0.998 | Val ACC: 0.885 | Features Left: 2381\n",
      "Epoch 029: | Loss: 0.06391 | Acc: 0.998 | Val ACC: 0.887 | Features Left: 2379\n",
      "Epoch 030: | Loss: 0.06351 | Acc: 0.998 | Val ACC: 0.887 | Features Left: 2376\n",
      "Epoch 031: | Loss: 0.06347 | Acc: 0.998 | Val ACC: 0.887 | Features Left: 2374\n",
      "Epoch 032: | Loss: 0.06343 | Acc: 0.998 | Val ACC: 0.887 | Features Left: 2370\n",
      "Epoch 033: | Loss: 0.06329 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2369\n",
      "Epoch 034: | Loss: 0.06361 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2367\n",
      "Epoch 035: | Loss: 0.06341 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2362\n",
      "Epoch 036: | Loss: 0.06296 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2358\n",
      "Epoch 037: | Loss: 0.06317 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2356\n",
      "Epoch 038: | Loss: 0.06287 | Acc: 0.998 | Val ACC: 0.885 | Features Left: 2354\n",
      "Epoch 039: | Loss: 0.06327 | Acc: 0.998 | Val ACC: 0.877 | Features Left: 2353\n",
      "Epoch 040: | Loss: 0.06293 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2350\n",
      "Epoch 041: | Loss: 0.06286 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2348\n",
      "Epoch 042: | Loss: 0.06277 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2343\n",
      "Epoch 043: | Loss: 0.06275 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2342\n",
      "Epoch 044: | Loss: 0.06271 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2338\n",
      "Epoch 045: | Loss: 0.06286 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2337\n",
      "Epoch 046: | Loss: 0.06282 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2337\n",
      "Epoch 047: | Loss: 0.06329 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2334\n",
      "Epoch 048: | Loss: 0.06255 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2333\n",
      "Epoch 049: | Loss: 0.06273 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2330\n",
      "Epoch 050: | Loss: 0.06259 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2327\n",
      "Epoch 051: | Loss: 0.06255 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2325\n",
      "Epoch 052: | Loss: 0.06289 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2322\n",
      "Epoch 053: | Loss: 0.06272 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2319\n",
      "Epoch 054: | Loss: 0.06266 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2317\n",
      "Epoch 055: | Loss: 0.06249 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2315\n",
      "Epoch 056: | Loss: 0.06259 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2312\n",
      "Epoch 057: | Loss: 0.06248 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2308\n",
      "Epoch 058: | Loss: 0.06255 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2303\n",
      "Epoch 059: | Loss: 0.06273 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2301\n",
      "Epoch 060: | Loss: 0.06258 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2300\n",
      "Epoch 061: | Loss: 0.06235 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2299\n",
      "Epoch 062: | Loss: 0.06256 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2297\n",
      "Epoch 063: | Loss: 0.06240 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2297\n",
      "Epoch 064: | Loss: 0.06243 | Acc: 0.998 | Val ACC: 0.885 | Features Left: 2295\n",
      "Epoch 065: | Loss: 0.06226 | Acc: 0.998 | Val ACC: 0.885 | Features Left: 2294\n",
      "Epoch 066: | Loss: 0.06270 | Acc: 0.998 | Val ACC: 0.885 | Features Left: 2291\n",
      "Epoch 067: | Loss: 0.06248 | Acc: 0.998 | Val ACC: 0.885 | Features Left: 2290\n",
      "Epoch 068: | Loss: 0.06253 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2285\n",
      "Epoch 069: | Loss: 0.06226 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2284\n",
      "Epoch 070: | Loss: 0.06233 | Acc: 0.998 | Val ACC: 0.877 | Features Left: 2281\n",
      "Epoch 071: | Loss: 0.06206 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2280\n",
      "Epoch 072: | Loss: 0.06228 | Acc: 0.998 | Val ACC: 0.877 | Features Left: 2279\n",
      "Epoch 073: | Loss: 0.06212 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2279\n",
      "Epoch 074: | Loss: 0.06209 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2276\n",
      "Epoch 075: | Loss: 0.06217 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2274\n",
      "Epoch 076: | Loss: 0.06214 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2272\n",
      "Epoch 077: | Loss: 0.06209 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2270\n",
      "Epoch 078: | Loss: 0.06220 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2269\n",
      "Epoch 079: | Loss: 0.06212 | Acc: 0.998 | Val ACC: 0.877 | Features Left: 2269\n",
      "Epoch 080: | Loss: 0.06204 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2268\n",
      "Epoch 081: | Loss: 0.06202 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2263\n",
      "Epoch 082: | Loss: 0.06206 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2259\n",
      "Epoch 083: | Loss: 0.06201 | Acc: 0.999 | Val ACC: 0.875 | Features Left: 2258\n",
      "Epoch 084: | Loss: 0.06183 | Acc: 0.998 | Val ACC: 0.875 | Features Left: 2257\n",
      "Epoch 085: | Loss: 0.06217 | Acc: 0.998 | Val ACC: 0.877 | Features Left: 2255\n",
      "Epoch 086: | Loss: 0.06225 | Acc: 0.998 | Val ACC: 0.877 | Features Left: 2253\n",
      "Epoch 087: | Loss: 0.06283 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2253\n",
      "Epoch 088: | Loss: 0.06258 | Acc: 0.998 | Val ACC: 0.877 | Features Left: 2249\n",
      "Epoch 089: | Loss: 0.06253 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2247\n",
      "Epoch 090: | Loss: 0.06199 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2245\n",
      "Epoch 091: | Loss: 0.06200 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2244\n",
      "Epoch 092: | Loss: 0.06203 | Acc: 0.998 | Val ACC: 0.877 | Features Left: 2242\n",
      "Epoch 093: | Loss: 0.06187 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2242\n",
      "Epoch 094: | Loss: 0.06204 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2240\n",
      "Epoch 095: | Loss: 0.06179 | Acc: 0.999 | Val ACC: 0.880 | Features Left: 2239\n",
      "Epoch 096: | Loss: 0.06227 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2236\n",
      "Epoch 097: | Loss: 0.06175 | Acc: 0.999 | Val ACC: 0.882 | Features Left: 2235\n",
      "Epoch 098: | Loss: 0.06183 | Acc: 0.998 | Val ACC: 0.880 | Features Left: 2235\n",
      "Epoch 099: | Loss: 0.06181 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2233\n"
     ]
    }
   ],
   "source": [
    "## STG on Features\n",
    "from Model import make_stg_models\n",
    "from Strategy import SyncSTGConcatStrategy\n",
    "from Server import SyncSTGServer\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "EMB_DIM = 128\n",
    "baselines_stg = {}\n",
    "for client_num in range(1, 6):\n",
    "    client_id_list = list(range(client_num))\n",
    "    courier = SyncLocalCourier(client_id_list)\n",
    "    loader = SimpleNumpyDataLoader(\n",
    "        clients_id_list=client_id_list,\n",
    "        data_source=(basehock_X, basehock_y)\n",
    "    )\n",
    "    loader_dict, input_dims = loader.distribute()\n",
    "    models, top_model = make_stg_models(input_dims)\n",
    "    # for model in models: print(model)\n",
    "    # print(top_model)\n",
    "    clients = []\n",
    "    for i, id in enumerate(client_id_list):\n",
    "        client = SyncFNNClient(\n",
    "            id=id,\n",
    "            model= models[i],\n",
    "            courier=courier,\n",
    "            train_loader=loader_dict[id]['train_loader'],\n",
    "            test_loader=loader_dict[id]['test_loader'],\n",
    "            config_dir='simple_config.ini')\n",
    "        clients.append(client)\n",
    "    strategy = SyncSTGConcatStrategy(courier=courier, clients=clients)\n",
    "    server = SyncSTGServer(\n",
    "        strategy=strategy,\n",
    "        courier=courier,\n",
    "        top_model=top_model,\n",
    "        emb_model=models[-1],\n",
    "        train_loader=loader_dict['server']['train_loader'],\n",
    "        test_loader=loader_dict['server']['test_loader'],\n",
    "        config_dir='simple_config.ini')\n",
    "    \n",
    "    print('Training Starts')\n",
    "    print(f'Number of Clients: {client_num}')\n",
    "    print('-'*89)\n",
    "    for epoch in range(100):\n",
    "        server.fit(epoch)\n",
    "        # count number of parameters      \n",
    "    history = server.get_history()\n",
    "    baselines_stg[client_num] = history  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Dual STG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There two important hyperparameters:\n",
    "* $\\lambda_{top}$ which controls how much the dual STG model punishes the embedding size\n",
    "* $\\sigma_{top}$ cnntrols the randomness\n",
    "* We may also need to introduce additional hyperparameters that controls when to start training the embedding layer STG based on the performance\n",
    "Let's begin with the most naive experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import STGEmbModel\n",
    "from stg.models import FeatureSelector\n",
    "class DualSTGModel(STGEmbModel):\n",
    "    def __init__(self, top_lam=0.1, top_sigma=1.0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.top_lam = top_lam\n",
    "        self.top_fs = FeatureSelector(self.output_dim, \n",
    "            sigma=top_sigma, device=torch.device('cuda'))\n",
    "        self.top_reg = self.top_fs.regularizer\n",
    "        self.top_sigma = self.top_fs.sigma\n",
    "        self.top_mu = self.top_fs.mu\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fs(x)\n",
    "        emb = self.mlp(x)\n",
    "        reduced_emb = self.top_fs(emb)\n",
    "        return reduced_emb\n",
    "\n",
    "    def get_top_reg_loss(self):\n",
    "        # reg = torch.mean(self.reg((self.mu + 0.5)/self.sigma))\n",
    "        top_reg = torch.mean(self.top_reg((self.top_fs.mu + 0.5)/self.top_sigma))\n",
    "        return top_reg * self.top_lam\n",
    "    \n",
    "    def get_emb_gates(self):\n",
    "        top_mu = self.top_fs.mu.detach().cpu().numpy()\n",
    "        top_z = np.maximum(np.minimum(top_mu, 1), 0)\n",
    "        return top_z, np.count_nonzero(top_z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "def make_dual_stg_models(input_dims, emb_dim=128, output_dim=1, top_lambda=0.1):\n",
    "    models = []\n",
    "    for input_dim in input_dims:\n",
    "        model = []\n",
    "        if input_dim >= 512:\n",
    "            model = DualSTGModel(input_dim=input_dim, output_dim=emb_dim, \n",
    "            hidden_dims=[512, 256], top_lam=top_lambda\n",
    "            )\n",
    "        else:\n",
    "            model = DualSTGModel(input_dim=input_dim, output_dim=emb_dim, \n",
    "            hidden_dims=[256], top_lam=top_lambda)\n",
    "        models.append(model)\n",
    "    top_model = nn.Sequential(\n",
    "        nn.Linear(len(input_dims)*128, 32), nn.ReLU(True), nn.Linear(32, output_dim), nn.Sigmoid()\n",
    "    )\n",
    "    return models, top_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Strategy import SyncSTGConcatStrategy\n",
    "class SyncDualSTGConcatStrategy(SyncSTGConcatStrategy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def number_of_embs(self):\n",
    "        num_embs = 0\n",
    "        for client in self.clients:\n",
    "            _, num = client.model.get_emb_gates()\n",
    "            num_embs += num\n",
    "        return num_embs\n",
    "\n",
    "    def update_all(self, loss, server_reg_loss):\n",
    "        reg_loss = server_reg_loss\n",
    "        # print(reg_loss)\n",
    "        for client in self.clients:\n",
    "            reg_loss += client.model.get_reg_loss()\n",
    "            reg_loss += client.model.get_top_reg_loss()\n",
    "        reg_loss = reg_loss/(len(self.clients)+1)\n",
    "        total_loss = reg_loss + loss\n",
    "        # print(total_loss)\n",
    "        total_loss.backward()\n",
    "        map(lambda client: client.update(), self.clients)\n",
    "        return total_loss.item(), reg_loss.item()\n",
    "       \n",
    "\n",
    "    def get_all_gates(self):\n",
    "        top_gates = []\n",
    "        btm_gates = []\n",
    "        for client in self.clients:\n",
    "            btm_gate, _ = client.model.get_gates()\n",
    "            top_gate, _ = client.model.get_emb_gates()\n",
    "            top_gates.append(top_gate)\n",
    "            btm_gates.append(btm_gate)\n",
    "        return top_gates, btm_gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Server import SyncSTGServer\n",
    "class SyncDualSTGServer(SyncSTGServer):\n",
    "    def __init__(self, record_at=20, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.gates = []\n",
    "        self.record_at = record_at\n",
    "\n",
    "    def fit(self, e):\n",
    "        train_acc = 0\n",
    "        train_loss = 0\n",
    "        for x, y in self.train_loader:\n",
    "            x = x.float().to(self.device)\n",
    "            y = y.float().to(self.device).view(-1, 1)\n",
    "            self.optimizer.zero_grad()\n",
    "            server_emb = self.emb_model(x)\n",
    "            clients_emb = self.strategy.aggregate()\n",
    "            emb = torch.cat([server_emb, clients_emb], 1)\n",
    "            server_reg_loss = self.emb_model.get_reg_loss()\n",
    "            server_reg_loss += self.emb_model.get_top_reg_loss()\n",
    "            out = self.model(emb)\n",
    "            loss = self.criterion(out, y)\n",
    "            acc = self.binary_acc(out.detach().cpu(), y.detach().cpu())\n",
    "            total_loss, reg_loss = self.strategy.update_all(loss, server_reg_loss)\n",
    "            self.optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_acc += acc\n",
    "        test_acc = self.evaluate()\n",
    "        _, num_feats = self.emb_model.get_gates()\n",
    "        num_feats += self.strategy.number_of_features()\n",
    "        num_embs = self.strategy.number_of_embs()\n",
    "        \n",
    "        print(f'Epoch {e+0:03}: |  Loss: {train_loss/len(self.train_loader):.5f} | Acc: {train_acc/len(self.train_loader):.3f} | Val ACC: {test_acc/len(self.test_loader):.3f} | Features Left: {num_feats} | Embeddings Left: {num_embs}')\n",
    "        print(f'Total loss {total_loss:.5f} | Reg loss {reg_loss:.5f}')\n",
    "        \n",
    "        self.train_acc.append(train_acc/len(self.train_loader))\n",
    "        self.test_acc.append(test_acc/len(self.test_loader))\n",
    "        if e % self.record_at == 0:\n",
    "            gates = self.strategy.get_all_gates()\n",
    "            self.gates.append(gates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 512])\n"
     ]
    }
   ],
   "source": [
    "model = DualSTGModel(input_dim=512, output_dim=128, hidden_dims=[512, 256], lam=0.1)\n",
    "model.train()\n",
    "x1 = torch.ones(100, 256)\n",
    "x2 = torch.zeros(100, 256)\n",
    "x = torch.cat([x1, x2], dim=1)\n",
    "x = x.requires_grad_()\n",
    "print(x.shape)\n",
    "y = torch.zeros(100, 128, requires_grad=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "z, num_feats =  model.get_gates()\n",
    "sns.heatmap(z.reshape(32, 16), vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_z, num_embs = model.get_emb_gates()\n",
    "sns.heatmap(top_z.reshape(16, 8), vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001814908697269857 0.06914692372083664 0.06913380324840546 0.14009563624858856\n",
      "0.0005737748579122126 0.06911212205886841 0.0690985769033432 0.1387844681739807\n",
      "0.0005636379937641323 0.06907729059457779 0.06906343251466751 0.1387043595314026\n",
      "0.0007177602383308113 0.0690423995256424 0.06902828812599182 0.13878844678401947\n",
      "0.0003050370141863823 0.069007508456707 0.06899314373731613 0.1383056938648224\n",
      "0.0004175739595666528 0.06897260993719101 0.06895800679922104 0.13834819197654724\n",
      "0.0003164559311699122 0.06893772631883621 0.06892286986112595 0.1381770521402359\n",
      "0.0002885769063141197 0.0689028725028038 0.06888773292303085 0.1380791813135147\n",
      "0.000151358763105236 0.06886806339025497 0.06885260343551636 0.13787202537059784\n",
      "0.00016343822062481195 0.06883331388235092 0.06881747394800186 0.1378142237663269\n",
      "0.00014520403055939823 0.06879863142967224 0.06878235191106796 0.13772618770599365\n",
      "0.00014972305507399142 0.06876403838396072 0.06874724477529526 0.13766101002693176\n",
      "8.202371100196615e-05 0.06872954219579697 0.06871213763952255 0.13752371072769165\n",
      "0.00010895010927924886 0.06869515031576157 0.06867705285549164 0.13748115301132202\n",
      "7.706919859629124e-05 0.06866087764501572 0.06864196807146072 0.13737991452217102\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x)\n",
    "    loss = criterion(y, out)\n",
    "    reg = model.get_reg_loss()\n",
    "    top_reg = model.get_top_reg_loss()\n",
    "    total_loss = loss + reg + top_reg\n",
    "    total_loss.backward()\n",
    "    print(loss.item(), reg.item(), top_reg.item(), total_loss.item())\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z, num_feats =  model.get_gates()\n",
    "sns.heatmap(z.reshape(32, 16), vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_z, num_embs = model.get_emb_gates()\n",
    "sns.heatmap(top_z.reshape(16, 8), vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, capture_output, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_lines\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36m_run_input_lines\u001b[1;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[0mpopen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1421\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    971\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\graphviz\\jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[1;34m(self, include, exclude, **_)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0minclude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minclude\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jupyter_mimetype\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0minclude\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexclude\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         return {mimetype: getattr(self, method_name)()\n\u001b[0m\u001b[0;32m     99\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 if mimetype in include}\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\graphviz\\jupyter_integration.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0minclude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minclude\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jupyter_mimetype\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0minclude\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexclude\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         return {mimetype: getattr(self, method_name)()\n\u001b[0m\u001b[0;32m     99\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 if mimetype in include}\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\graphviz\\jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_image_svg_xml\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_image_svg_xml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;34m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSVG_ENCODING\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;34m'<?xml version='\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \"\"\"\n\u001b[1;32m---> 99\u001b[1;33m         return self._pipe_legacy(format,\n\u001b[0m\u001b[0;32m    100\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\graphviz\\_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m                               category=category)\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[1;34m(self, format, renderer, formatter, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    112\u001b[0m                      \u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                      encoding: typing.Optional[str] = None) -> typing.Union[bytes, str]:\n\u001b[1;32m--> 114\u001b[1;33m         return self._pipe_future(format,\n\u001b[0m\u001b[0;32m    115\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[1;34m(self, format, renderer, formatter, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[1;31m# common case: both stdin and stdout need the same encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipe_lines_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[0mraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\graphviz\\backend\\piping.py\u001b[0m in \u001b[0;36mpipe_lines_string\u001b[1;34m(engine, format, input_lines, encoding, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'input_lines'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m     \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, capture_output, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2582766a160>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz \n",
    "torchviz.make_dot(total_loss, params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: Feature Index 0-2430\n",
      "Server : Feature Index 2431-4861\n",
      "Training Starts\n",
      "Number of Clients: 1\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: |  Loss: 0.67675 | Acc: 0.635 | Val ACC: 0.902 | Features Left: 1543 | Embeddings Left: 69\n",
      "Total loss 0.75904 | Reg loss 0.13797\n",
      "Epoch 001: |  Loss: 0.35869 | Acc: 0.969 | Val ACC: 0.957 | Features Left: 1684 | Embeddings Left: 69\n",
      "Total loss 0.22392 | Reg loss 0.13811\n",
      "Epoch 002: |  Loss: 0.03464 | Acc: 0.989 | Val ACC: 0.952 | Features Left: 1820 | Embeddings Left: 69\n",
      "Total loss 0.13855 | Reg loss 0.13828\n",
      "Epoch 003: |  Loss: 0.00915 | Acc: 0.998 | Val ACC: 0.965 | Features Left: 1825 | Embeddings Left: 69\n",
      "Total loss 0.13855 | Reg loss 0.13828\n",
      "Epoch 004: |  Loss: 0.00157 | Acc: 0.999 | Val ACC: 0.957 | Features Left: 1802 | Embeddings Left: 69\n",
      "Total loss 0.13823 | Reg loss 0.13821\n",
      "Epoch 005: |  Loss: 0.00042 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1758 | Embeddings Left: 69\n",
      "Total loss 0.13814 | Reg loss 0.13811\n",
      "Epoch 006: |  Loss: 0.00014 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1711 | Embeddings Left: 69\n",
      "Total loss 0.13802 | Reg loss 0.13801\n",
      "Epoch 007: |  Loss: 0.00012 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1675 | Embeddings Left: 69\n",
      "Total loss 0.13790 | Reg loss 0.13789\n",
      "Epoch 008: |  Loss: 0.00011 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1649 | Embeddings Left: 69\n",
      "Total loss 0.13778 | Reg loss 0.13776\n",
      "Epoch 009: |  Loss: 0.00010 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1618 | Embeddings Left: 69\n",
      "Total loss 0.13765 | Reg loss 0.13763\n",
      "Epoch 010: |  Loss: 0.00010 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1600 | Embeddings Left: 69\n",
      "Total loss 0.13751 | Reg loss 0.13750\n",
      "Epoch 011: |  Loss: 0.00009 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1577 | Embeddings Left: 69\n",
      "Total loss 0.13737 | Reg loss 0.13735\n",
      "Epoch 012: |  Loss: 0.00009 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1558 | Embeddings Left: 69\n",
      "Total loss 0.13722 | Reg loss 0.13721\n",
      "Epoch 013: |  Loss: 0.00008 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1541 | Embeddings Left: 69\n",
      "Total loss 0.13707 | Reg loss 0.13706\n",
      "Epoch 014: |  Loss: 0.00008 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1528 | Embeddings Left: 69\n",
      "Total loss 0.13692 | Reg loss 0.13690\n",
      "Epoch 015: |  Loss: 0.00008 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1515 | Embeddings Left: 69\n",
      "Total loss 0.13676 | Reg loss 0.13674\n",
      "Epoch 016: |  Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1501 | Embeddings Left: 69\n",
      "Total loss 0.13659 | Reg loss 0.13658\n",
      "Epoch 017: |  Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1490 | Embeddings Left: 69\n",
      "Total loss 0.13642 | Reg loss 0.13641\n",
      "Epoch 018: |  Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1475 | Embeddings Left: 69\n",
      "Total loss 0.13625 | Reg loss 0.13624\n",
      "Epoch 019: |  Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1466 | Embeddings Left: 69\n",
      "Total loss 0.13608 | Reg loss 0.13607\n",
      "Epoch 020: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1455 | Embeddings Left: 69\n",
      "Total loss 0.13590 | Reg loss 0.13589\n",
      "Epoch 021: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1450 | Embeddings Left: 69\n",
      "Total loss 0.13572 | Reg loss 0.13570\n",
      "Epoch 022: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1440 | Embeddings Left: 69\n",
      "Total loss 0.13553 | Reg loss 0.13552\n",
      "Epoch 023: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1430 | Embeddings Left: 69\n",
      "Total loss 0.13534 | Reg loss 0.13533\n",
      "Epoch 024: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1423 | Embeddings Left: 69\n",
      "Total loss 0.13515 | Reg loss 0.13514\n",
      "Epoch 025: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1415 | Embeddings Left: 69\n",
      "Total loss 0.13495 | Reg loss 0.13494\n",
      "Epoch 026: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1404 | Embeddings Left: 69\n",
      "Total loss 0.13475 | Reg loss 0.13474\n",
      "Epoch 027: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1398 | Embeddings Left: 69\n",
      "Total loss 0.13455 | Reg loss 0.13454\n",
      "Epoch 028: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1388 | Embeddings Left: 69\n",
      "Total loss 0.13434 | Reg loss 0.13433\n",
      "Epoch 029: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1380 | Embeddings Left: 69\n",
      "Total loss 0.13413 | Reg loss 0.13412\n",
      "Epoch 030: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1375 | Embeddings Left: 69\n",
      "Total loss 0.13392 | Reg loss 0.13391\n",
      "Epoch 031: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1371 | Embeddings Left: 69\n",
      "Total loss 0.13370 | Reg loss 0.13369\n",
      "Epoch 032: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1366 | Embeddings Left: 69\n",
      "Total loss 0.13349 | Reg loss 0.13348\n",
      "Epoch 033: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1360 | Embeddings Left: 69\n",
      "Total loss 0.13326 | Reg loss 0.13326\n",
      "Epoch 034: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1356 | Embeddings Left: 69\n",
      "Total loss 0.13304 | Reg loss 0.13303\n",
      "Epoch 035: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1349 | Embeddings Left: 69\n",
      "Total loss 0.13282 | Reg loss 0.13281\n",
      "Epoch 036: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1345 | Embeddings Left: 69\n",
      "Total loss 0.13259 | Reg loss 0.13258\n",
      "Epoch 037: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1340 | Embeddings Left: 69\n",
      "Total loss 0.13236 | Reg loss 0.13235\n",
      "Epoch 038: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1337 | Embeddings Left: 69\n",
      "Total loss 0.13212 | Reg loss 0.13211\n",
      "Epoch 039: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1334 | Embeddings Left: 69\n",
      "Total loss 0.13189 | Reg loss 0.13188\n",
      "Epoch 040: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1331 | Embeddings Left: 69\n",
      "Total loss 0.13165 | Reg loss 0.13164\n",
      "Epoch 041: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1325 | Embeddings Left: 69\n",
      "Total loss 0.13141 | Reg loss 0.13140\n",
      "Epoch 042: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1322 | Embeddings Left: 69\n",
      "Total loss 0.13116 | Reg loss 0.13115\n",
      "Epoch 043: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1319 | Embeddings Left: 69\n",
      "Total loss 0.13092 | Reg loss 0.13091\n",
      "Epoch 044: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1315 | Embeddings Left: 69\n",
      "Total loss 0.13067 | Reg loss 0.13066\n",
      "Epoch 045: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1313 | Embeddings Left: 69\n",
      "Total loss 0.13042 | Reg loss 0.13041\n",
      "Epoch 046: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1310 | Embeddings Left: 69\n",
      "Total loss 0.13017 | Reg loss 0.13016\n",
      "Epoch 047: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1308 | Embeddings Left: 69\n",
      "Total loss 0.12992 | Reg loss 0.12991\n",
      "Epoch 048: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1303 | Embeddings Left: 69\n",
      "Total loss 0.12966 | Reg loss 0.12965\n",
      "Epoch 049: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1301 | Embeddings Left: 69\n",
      "Total loss 0.12941 | Reg loss 0.12939\n",
      "Epoch 050: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1299 | Embeddings Left: 69\n",
      "Total loss 0.12915 | Reg loss 0.12914\n",
      "Epoch 051: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1295 | Embeddings Left: 69\n",
      "Total loss 0.12889 | Reg loss 0.12887\n",
      "Epoch 052: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1293 | Embeddings Left: 69\n",
      "Total loss 0.12863 | Reg loss 0.12861\n",
      "Epoch 053: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1292 | Embeddings Left: 69\n",
      "Total loss 0.12836 | Reg loss 0.12835\n",
      "Epoch 054: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1288 | Embeddings Left: 69\n",
      "Total loss 0.12810 | Reg loss 0.12808\n",
      "Epoch 055: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 1285 | Embeddings Left: 69\n",
      "Total loss 0.12783 | Reg loss 0.12781\n",
      "Epoch 056: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 1283 | Embeddings Left: 69\n",
      "Total loss 0.12756 | Reg loss 0.12755\n",
      "Epoch 057: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 1282 | Embeddings Left: 69\n",
      "Total loss 0.12729 | Reg loss 0.12727\n",
      "Epoch 058: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 1282 | Embeddings Left: 69\n",
      "Total loss 0.12702 | Reg loss 0.12700\n",
      "Epoch 059: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 1278 | Embeddings Left: 69\n",
      "Total loss 0.12674 | Reg loss 0.12673\n",
      "Epoch 060: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 1277 | Embeddings Left: 69\n",
      "Total loss 0.12647 | Reg loss 0.12645\n",
      "Epoch 061: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 1276 | Embeddings Left: 69\n",
      "Total loss 0.12619 | Reg loss 0.12618\n",
      "Epoch 062: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 1272 | Embeddings Left: 69\n",
      "Total loss 0.12591 | Reg loss 0.12590\n",
      "Epoch 063: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 1271 | Embeddings Left: 69\n",
      "Total loss 0.12564 | Reg loss 0.12562\n",
      "Epoch 064: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 1269 | Embeddings Left: 69\n",
      "Total loss 0.12536 | Reg loss 0.12534\n",
      "Epoch 065: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 1268 | Embeddings Left: 69\n",
      "Total loss 0.12507 | Reg loss 0.12506\n",
      "Epoch 066: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 1266 | Embeddings Left: 69\n",
      "Total loss 0.12479 | Reg loss 0.12478\n",
      "Epoch 067: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.952 | Features Left: 1264 | Embeddings Left: 69\n",
      "Total loss 0.12450 | Reg loss 0.12449\n",
      "Epoch 068: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.952 | Features Left: 1264 | Embeddings Left: 69\n",
      "Total loss 0.12422 | Reg loss 0.12421\n",
      "Epoch 069: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.952 | Features Left: 1262 | Embeddings Left: 69\n",
      "Total loss 0.12393 | Reg loss 0.12392\n",
      "Epoch 070: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 1259 | Embeddings Left: 69\n",
      "Total loss 0.12364 | Reg loss 0.12363\n",
      "Epoch 071: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 1258 | Embeddings Left: 69\n",
      "Total loss 0.12335 | Reg loss 0.12334\n",
      "Epoch 072: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 1257 | Embeddings Left: 69\n",
      "Total loss 0.12306 | Reg loss 0.12305\n",
      "Epoch 073: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 1257 | Embeddings Left: 69\n",
      "Total loss 0.12277 | Reg loss 0.12276\n",
      "Epoch 074: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 1255 | Embeddings Left: 69\n",
      "Total loss 0.12248 | Reg loss 0.12247\n",
      "Epoch 075: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 1255 | Embeddings Left: 69\n",
      "Total loss 0.12218 | Reg loss 0.12217\n",
      "Epoch 076: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1251 | Embeddings Left: 69\n",
      "Total loss 0.12189 | Reg loss 0.12188\n",
      "Epoch 077: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1248 | Embeddings Left: 69\n",
      "Total loss 0.12159 | Reg loss 0.12159\n",
      "Epoch 078: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1246 | Embeddings Left: 69\n",
      "Total loss 0.12130 | Reg loss 0.12129\n",
      "Epoch 079: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1242 | Embeddings Left: 69\n",
      "Total loss 0.12100 | Reg loss 0.12099\n",
      "Epoch 080: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1240 | Embeddings Left: 69\n",
      "Total loss 0.12071 | Reg loss 0.12070\n",
      "Epoch 081: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1239 | Embeddings Left: 69\n",
      "Total loss 0.12041 | Reg loss 0.12040\n",
      "Epoch 082: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1239 | Embeddings Left: 69\n",
      "Total loss 0.12012 | Reg loss 0.12011\n",
      "Epoch 083: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1238 | Embeddings Left: 69\n",
      "Total loss 0.11982 | Reg loss 0.11981\n",
      "Epoch 084: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1235 | Embeddings Left: 69\n",
      "Total loss 0.11952 | Reg loss 0.11951\n",
      "Epoch 085: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1234 | Embeddings Left: 69\n",
      "Total loss 0.11923 | Reg loss 0.11922\n",
      "Epoch 086: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1233 | Embeddings Left: 69\n",
      "Total loss 0.11893 | Reg loss 0.11892\n",
      "Epoch 087: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1232 | Embeddings Left: 69\n",
      "Total loss 0.11863 | Reg loss 0.11862\n",
      "Epoch 088: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1231 | Embeddings Left: 69\n",
      "Total loss 0.11833 | Reg loss 0.11833\n",
      "Epoch 089: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1231 | Embeddings Left: 69\n",
      "Total loss 0.11804 | Reg loss 0.11803\n",
      "Epoch 090: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1230 | Embeddings Left: 69\n",
      "Total loss 0.11774 | Reg loss 0.11773\n",
      "Epoch 091: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1228 | Embeddings Left: 69\n",
      "Total loss 0.11744 | Reg loss 0.11744\n",
      "Epoch 092: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1228 | Embeddings Left: 69\n",
      "Total loss 0.11715 | Reg loss 0.11714\n",
      "Epoch 093: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 1226 | Embeddings Left: 69\n",
      "Total loss 0.11685 | Reg loss 0.11684\n",
      "Epoch 094: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1226 | Embeddings Left: 69\n",
      "Total loss 0.11656 | Reg loss 0.11655\n",
      "Epoch 095: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1225 | Embeddings Left: 69\n",
      "Total loss 0.11626 | Reg loss 0.11625\n",
      "Epoch 096: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1225 | Embeddings Left: 69\n",
      "Total loss 0.11597 | Reg loss 0.11596\n",
      "Epoch 097: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1225 | Embeddings Left: 69\n",
      "Total loss 0.11567 | Reg loss 0.11566\n",
      "Epoch 098: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1224 | Embeddings Left: 69\n",
      "Total loss 0.11538 | Reg loss 0.11537\n",
      "Epoch 099: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 1224 | Embeddings Left: 69\n",
      "Total loss 0.11508 | Reg loss 0.11507\n",
      "Client 0: Feature Index 0-1620\n",
      "Client 1: Feature Index 1621-3241\n",
      "Server : Feature Index 3242-4861\n",
      "Training Starts\n",
      "Number of Clients: 2\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: |  Loss: 0.68589 | Acc: 0.539 | Val ACC: 0.792 | Features Left: 1856 | Embeddings Left: 138\n",
      "Total loss 0.80626 | Reg loss 0.13805\n",
      "Epoch 001: |  Loss: 0.46396 | Acc: 0.926 | Val ACC: 0.922 | Features Left: 1913 | Embeddings Left: 138\n",
      "Total loss 0.32383 | Reg loss 0.13813\n",
      "Epoch 002: |  Loss: 0.08930 | Acc: 0.970 | Val ACC: 0.927 | Features Left: 2043 | Embeddings Left: 138\n",
      "Total loss 0.15300 | Reg loss 0.13828\n",
      "Epoch 003: |  Loss: 0.02885 | Acc: 0.987 | Val ACC: 0.927 | Features Left: 2077 | Embeddings Left: 138\n",
      "Total loss 0.14205 | Reg loss 0.13830\n",
      "Epoch 004: |  Loss: 0.02479 | Acc: 0.990 | Val ACC: 0.942 | Features Left: 2082 | Embeddings Left: 138\n",
      "Total loss 0.13913 | Reg loss 0.13828\n",
      "Epoch 005: |  Loss: 0.03990 | Acc: 0.988 | Val ACC: 0.915 | Features Left: 2076 | Embeddings Left: 138\n",
      "Total loss 0.28721 | Reg loss 0.13823\n",
      "Epoch 006: |  Loss: 0.01967 | Acc: 0.993 | Val ACC: 0.937 | Features Left: 2075 | Embeddings Left: 138\n",
      "Total loss 0.14345 | Reg loss 0.13818\n",
      "Epoch 007: |  Loss: 0.00581 | Acc: 0.998 | Val ACC: 0.937 | Features Left: 2083 | Embeddings Left: 138\n",
      "Total loss 0.13863 | Reg loss 0.13814\n",
      "Epoch 008: |  Loss: 0.00309 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 2075 | Embeddings Left: 138\n",
      "Total loss 0.13848 | Reg loss 0.13811\n",
      "Epoch 009: |  Loss: 0.00195 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 2066 | Embeddings Left: 138\n",
      "Total loss 0.13836 | Reg loss 0.13807\n",
      "Epoch 010: |  Loss: 0.00137 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 2058 | Embeddings Left: 138\n",
      "Total loss 0.13824 | Reg loss 0.13804\n",
      "Epoch 011: |  Loss: 0.00099 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 2045 | Embeddings Left: 138\n",
      "Total loss 0.13815 | Reg loss 0.13800\n",
      "Epoch 012: |  Loss: 0.00075 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 2035 | Embeddings Left: 138\n",
      "Total loss 0.13806 | Reg loss 0.13796\n",
      "Epoch 013: |  Loss: 0.00053 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 2022 | Embeddings Left: 138\n",
      "Total loss 0.13798 | Reg loss 0.13791\n",
      "Epoch 014: |  Loss: 0.00038 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 2015 | Embeddings Left: 138\n",
      "Total loss 0.13791 | Reg loss 0.13787\n",
      "Epoch 015: |  Loss: 0.00028 | Acc: 1.000 | Val ACC: 0.940 | Features Left: 1998 | Embeddings Left: 138\n",
      "Total loss 0.13785 | Reg loss 0.13782\n",
      "Epoch 016: |  Loss: 0.00021 | Acc: 1.000 | Val ACC: 0.937 | Features Left: 1992 | Embeddings Left: 138\n",
      "Total loss 0.13779 | Reg loss 0.13776\n",
      "Epoch 017: |  Loss: 0.00017 | Acc: 1.000 | Val ACC: 0.937 | Features Left: 1975 | Embeddings Left: 138\n",
      "Total loss 0.13773 | Reg loss 0.13771\n",
      "Epoch 018: |  Loss: 0.00014 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1965 | Embeddings Left: 138\n",
      "Total loss 0.13767 | Reg loss 0.13765\n",
      "Epoch 019: |  Loss: 0.00011 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1959 | Embeddings Left: 138\n",
      "Total loss 0.13760 | Reg loss 0.13759\n",
      "Epoch 020: |  Loss: 0.00010 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1955 | Embeddings Left: 138\n",
      "Total loss 0.13754 | Reg loss 0.13753\n",
      "Epoch 021: |  Loss: 0.00008 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1948 | Embeddings Left: 138\n",
      "Total loss 0.13748 | Reg loss 0.13747\n",
      "Epoch 022: |  Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1943 | Embeddings Left: 138\n",
      "Total loss 0.13742 | Reg loss 0.13741\n",
      "Epoch 023: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1941 | Embeddings Left: 138\n",
      "Total loss 0.13735 | Reg loss 0.13734\n",
      "Epoch 024: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1935 | Embeddings Left: 138\n",
      "Total loss 0.13728 | Reg loss 0.13728\n",
      "Epoch 025: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1928 | Embeddings Left: 138\n",
      "Total loss 0.13722 | Reg loss 0.13721\n",
      "Epoch 026: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.935 | Features Left: 1925 | Embeddings Left: 138\n",
      "Total loss 0.13715 | Reg loss 0.13714\n",
      "Epoch 027: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1915 | Embeddings Left: 138\n",
      "Total loss 0.13708 | Reg loss 0.13707\n",
      "Epoch 028: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1910 | Embeddings Left: 138\n",
      "Total loss 0.13700 | Reg loss 0.13700\n",
      "Epoch 029: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1903 | Embeddings Left: 138\n",
      "Total loss 0.13693 | Reg loss 0.13693\n",
      "Epoch 030: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1894 | Embeddings Left: 138\n",
      "Total loss 0.13686 | Reg loss 0.13686\n",
      "Epoch 031: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1890 | Embeddings Left: 138\n",
      "Total loss 0.13678 | Reg loss 0.13678\n",
      "Epoch 032: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1887 | Embeddings Left: 138\n",
      "Total loss 0.13671 | Reg loss 0.13670\n",
      "Epoch 033: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.932 | Features Left: 1885 | Embeddings Left: 138\n",
      "Total loss 0.13663 | Reg loss 0.13663\n",
      "Epoch 034: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1882 | Embeddings Left: 138\n",
      "Total loss 0.13655 | Reg loss 0.13655\n",
      "Epoch 035: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1877 | Embeddings Left: 138\n",
      "Total loss 0.13647 | Reg loss 0.13647\n",
      "Epoch 036: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1873 | Embeddings Left: 138\n",
      "Total loss 0.13639 | Reg loss 0.13639\n",
      "Epoch 037: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1873 | Embeddings Left: 138\n",
      "Total loss 0.13631 | Reg loss 0.13631\n",
      "Epoch 038: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1873 | Embeddings Left: 138\n",
      "Total loss 0.13623 | Reg loss 0.13623\n",
      "Epoch 039: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1869 | Embeddings Left: 138\n",
      "Total loss 0.13614 | Reg loss 0.13614\n",
      "Epoch 040: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1869 | Embeddings Left: 138\n",
      "Total loss 0.13606 | Reg loss 0.13606\n",
      "Epoch 041: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1861 | Embeddings Left: 138\n",
      "Total loss 0.13597 | Reg loss 0.13597\n",
      "Epoch 042: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1858 | Embeddings Left: 138\n",
      "Total loss 0.13589 | Reg loss 0.13589\n",
      "Epoch 043: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1858 | Embeddings Left: 138\n",
      "Total loss 0.13580 | Reg loss 0.13580\n",
      "Epoch 044: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1857 | Embeddings Left: 138\n",
      "Total loss 0.13571 | Reg loss 0.13571\n",
      "Epoch 045: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1853 | Embeddings Left: 138\n",
      "Total loss 0.13562 | Reg loss 0.13562\n",
      "Epoch 046: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1853 | Embeddings Left: 138\n",
      "Total loss 0.13553 | Reg loss 0.13553\n",
      "Epoch 047: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1846 | Embeddings Left: 138\n",
      "Total loss 0.13544 | Reg loss 0.13544\n",
      "Epoch 048: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1845 | Embeddings Left: 138\n",
      "Total loss 0.13535 | Reg loss 0.13535\n",
      "Epoch 049: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1842 | Embeddings Left: 138\n",
      "Total loss 0.13525 | Reg loss 0.13525\n",
      "Epoch 050: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1842 | Embeddings Left: 138\n",
      "Total loss 0.13516 | Reg loss 0.13516\n",
      "Epoch 051: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1842 | Embeddings Left: 138\n",
      "Total loss 0.13506 | Reg loss 0.13506\n",
      "Epoch 052: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1840 | Embeddings Left: 138\n",
      "Total loss 0.13497 | Reg loss 0.13497\n",
      "Epoch 053: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1838 | Embeddings Left: 138\n",
      "Total loss 0.13487 | Reg loss 0.13487\n",
      "Epoch 054: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1833 | Embeddings Left: 138\n",
      "Total loss 0.13477 | Reg loss 0.13477\n",
      "Epoch 055: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1833 | Embeddings Left: 138\n",
      "Total loss 0.13468 | Reg loss 0.13468\n",
      "Epoch 056: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1829 | Embeddings Left: 138\n",
      "Total loss 0.13458 | Reg loss 0.13458\n",
      "Epoch 057: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1828 | Embeddings Left: 138\n",
      "Total loss 0.13448 | Reg loss 0.13448\n",
      "Epoch 058: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1826 | Embeddings Left: 138\n",
      "Total loss 0.13438 | Reg loss 0.13438\n",
      "Epoch 059: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1825 | Embeddings Left: 138\n",
      "Total loss 0.13428 | Reg loss 0.13428\n",
      "Epoch 060: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1823 | Embeddings Left: 138\n",
      "Total loss 0.13417 | Reg loss 0.13417\n",
      "Epoch 061: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1822 | Embeddings Left: 138\n",
      "Total loss 0.13407 | Reg loss 0.13407\n",
      "Epoch 062: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1820 | Embeddings Left: 138\n",
      "Total loss 0.13397 | Reg loss 0.13397\n",
      "Epoch 063: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1816 | Embeddings Left: 138\n",
      "Total loss 0.13386 | Reg loss 0.13386\n",
      "Epoch 064: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1813 | Embeddings Left: 138\n",
      "Total loss 0.13376 | Reg loss 0.13376\n",
      "Epoch 065: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1808 | Embeddings Left: 138\n",
      "Total loss 0.13365 | Reg loss 0.13365\n",
      "Epoch 066: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1805 | Embeddings Left: 138\n",
      "Total loss 0.13355 | Reg loss 0.13355\n",
      "Epoch 067: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1801 | Embeddings Left: 138\n",
      "Total loss 0.13344 | Reg loss 0.13344\n",
      "Epoch 068: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1800 | Embeddings Left: 138\n",
      "Total loss 0.13333 | Reg loss 0.13333\n",
      "Epoch 069: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1799 | Embeddings Left: 138\n",
      "Total loss 0.13322 | Reg loss 0.13322\n",
      "Epoch 070: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1798 | Embeddings Left: 138\n",
      "Total loss 0.13311 | Reg loss 0.13311\n",
      "Epoch 071: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1796 | Embeddings Left: 138\n",
      "Total loss 0.13300 | Reg loss 0.13300\n",
      "Epoch 072: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1794 | Embeddings Left: 138\n",
      "Total loss 0.13289 | Reg loss 0.13289\n",
      "Epoch 073: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.930 | Features Left: 1792 | Embeddings Left: 138\n",
      "Total loss 0.13278 | Reg loss 0.13278\n",
      "Epoch 074: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1792 | Embeddings Left: 138\n",
      "Total loss 0.13267 | Reg loss 0.13267\n",
      "Epoch 075: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1790 | Embeddings Left: 138\n",
      "Total loss 0.13256 | Reg loss 0.13256\n",
      "Epoch 076: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1790 | Embeddings Left: 138\n",
      "Total loss 0.13245 | Reg loss 0.13245\n",
      "Epoch 077: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1790 | Embeddings Left: 138\n",
      "Total loss 0.13233 | Reg loss 0.13233\n",
      "Epoch 078: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1790 | Embeddings Left: 138\n",
      "Total loss 0.13222 | Reg loss 0.13222\n",
      "Epoch 079: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1789 | Embeddings Left: 138\n",
      "Total loss 0.13211 | Reg loss 0.13211\n",
      "Epoch 080: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1787 | Embeddings Left: 138\n",
      "Total loss 0.13199 | Reg loss 0.13199\n",
      "Epoch 081: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1784 | Embeddings Left: 138\n",
      "Total loss 0.13188 | Reg loss 0.13188\n",
      "Epoch 082: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1784 | Embeddings Left: 138\n",
      "Total loss 0.13176 | Reg loss 0.13176\n",
      "Epoch 083: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1783 | Embeddings Left: 138\n",
      "Total loss 0.13165 | Reg loss 0.13164\n",
      "Epoch 084: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1782 | Embeddings Left: 138\n",
      "Total loss 0.13153 | Reg loss 0.13153\n",
      "Epoch 085: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1781 | Embeddings Left: 138\n",
      "Total loss 0.13141 | Reg loss 0.13141\n",
      "Epoch 086: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1779 | Embeddings Left: 138\n",
      "Total loss 0.13129 | Reg loss 0.13129\n",
      "Epoch 087: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1779 | Embeddings Left: 138\n",
      "Total loss 0.13118 | Reg loss 0.13117\n",
      "Epoch 088: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1777 | Embeddings Left: 138\n",
      "Total loss 0.13106 | Reg loss 0.13106\n",
      "Epoch 089: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1777 | Embeddings Left: 138\n",
      "Total loss 0.13094 | Reg loss 0.13094\n",
      "Epoch 090: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1772 | Embeddings Left: 138\n",
      "Total loss 0.13082 | Reg loss 0.13082\n",
      "Epoch 091: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1772 | Embeddings Left: 138\n",
      "Total loss 0.13070 | Reg loss 0.13070\n",
      "Epoch 092: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1771 | Embeddings Left: 138\n",
      "Total loss 0.13058 | Reg loss 0.13058\n",
      "Epoch 093: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1768 | Embeddings Left: 138\n",
      "Total loss 0.13046 | Reg loss 0.13046\n",
      "Epoch 094: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1767 | Embeddings Left: 138\n",
      "Total loss 0.13034 | Reg loss 0.13033\n",
      "Epoch 095: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1767 | Embeddings Left: 138\n",
      "Total loss 0.13021 | Reg loss 0.13021\n",
      "Epoch 096: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.927 | Features Left: 1766 | Embeddings Left: 138\n",
      "Total loss 0.13009 | Reg loss 0.13009\n",
      "Epoch 097: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.925 | Features Left: 1765 | Embeddings Left: 138\n",
      "Total loss 0.12997 | Reg loss 0.12997\n",
      "Epoch 098: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.925 | Features Left: 1764 | Embeddings Left: 138\n",
      "Total loss 0.12985 | Reg loss 0.12985\n",
      "Epoch 099: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.925 | Features Left: 1762 | Embeddings Left: 138\n",
      "Total loss 0.12972 | Reg loss 0.12972\n",
      "Client 0: Feature Index 0-1215\n",
      "Client 1: Feature Index 1216-2431\n",
      "Client 2: Feature Index 2432-3646\n",
      "Server : Feature Index 3647-4861\n",
      "Training Starts\n",
      "Number of Clients: 3\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: |  Loss: 0.69036 | Acc: 0.554 | Val ACC: 0.784 | Features Left: 1959 | Embeddings Left: 188\n",
      "Total loss 0.82003 | Reg loss 0.13809\n",
      "Epoch 001: |  Loss: 0.55908 | Acc: 0.902 | Val ACC: 0.890 | Features Left: 1999 | Embeddings Left: 188\n",
      "Total loss 0.46743 | Reg loss 0.13812\n",
      "Epoch 002: |  Loss: 0.18904 | Acc: 0.933 | Val ACC: 0.927 | Features Left: 2130 | Embeddings Left: 188\n",
      "Total loss 0.22696 | Reg loss 0.13827\n",
      "Epoch 003: |  Loss: 0.07527 | Acc: 0.973 | Val ACC: 0.922 | Features Left: 2180 | Embeddings Left: 188\n",
      "Total loss 0.17503 | Reg loss 0.13831\n",
      "Epoch 004: |  Loss: 0.07883 | Acc: 0.972 | Val ACC: 0.922 | Features Left: 2205 | Embeddings Left: 188\n",
      "Total loss 0.19729 | Reg loss 0.13830\n",
      "Epoch 005: |  Loss: 0.12704 | Acc: 0.971 | Val ACC: 0.900 | Features Left: 2220 | Embeddings Left: 188\n",
      "Total loss 0.15029 | Reg loss 0.13825\n",
      "Epoch 006: |  Loss: 0.05089 | Acc: 0.982 | Val ACC: 0.930 | Features Left: 2229 | Embeddings Left: 188\n",
      "Total loss 0.16471 | Reg loss 0.13822\n",
      "Epoch 007: |  Loss: 0.02220 | Acc: 0.994 | Val ACC: 0.920 | Features Left: 2233 | Embeddings Left: 188\n",
      "Total loss 0.15743 | Reg loss 0.13823\n",
      "Epoch 008: |  Loss: 0.01213 | Acc: 0.997 | Val ACC: 0.912 | Features Left: 2236 | Embeddings Left: 188\n",
      "Total loss 0.14294 | Reg loss 0.13823\n",
      "Epoch 009: |  Loss: 0.00596 | Acc: 0.999 | Val ACC: 0.917 | Features Left: 2233 | Embeddings Left: 188\n",
      "Total loss 0.14282 | Reg loss 0.13824\n",
      "Epoch 010: |  Loss: 0.00395 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2225 | Embeddings Left: 188\n",
      "Total loss 0.14090 | Reg loss 0.13823\n",
      "Epoch 011: |  Loss: 0.00272 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2221 | Embeddings Left: 188\n",
      "Total loss 0.13987 | Reg loss 0.13822\n",
      "Epoch 012: |  Loss: 0.00201 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2214 | Embeddings Left: 188\n",
      "Total loss 0.13938 | Reg loss 0.13821\n",
      "Epoch 013: |  Loss: 0.00156 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2213 | Embeddings Left: 188\n",
      "Total loss 0.13914 | Reg loss 0.13820\n",
      "Epoch 014: |  Loss: 0.00126 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 2204 | Embeddings Left: 188\n",
      "Total loss 0.13893 | Reg loss 0.13818\n",
      "Epoch 015: |  Loss: 0.00105 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 2200 | Embeddings Left: 188\n",
      "Total loss 0.13876 | Reg loss 0.13816\n",
      "Epoch 016: |  Loss: 0.00087 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2190 | Embeddings Left: 188\n",
      "Total loss 0.13860 | Reg loss 0.13814\n",
      "Epoch 017: |  Loss: 0.00075 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2183 | Embeddings Left: 188\n",
      "Total loss 0.13850 | Reg loss 0.13811\n",
      "Epoch 018: |  Loss: 0.00065 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2181 | Embeddings Left: 188\n",
      "Total loss 0.13841 | Reg loss 0.13809\n",
      "Epoch 019: |  Loss: 0.00057 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 2175 | Embeddings Left: 188\n",
      "Total loss 0.13833 | Reg loss 0.13806\n",
      "Epoch 020: |  Loss: 0.00050 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 2168 | Embeddings Left: 188\n",
      "Total loss 0.13826 | Reg loss 0.13803\n",
      "Epoch 021: |  Loss: 0.00045 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 2162 | Embeddings Left: 188\n",
      "Total loss 0.13821 | Reg loss 0.13800\n",
      "Epoch 022: |  Loss: 0.00040 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 2155 | Embeddings Left: 188\n",
      "Total loss 0.13815 | Reg loss 0.13797\n",
      "Epoch 023: |  Loss: 0.00036 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 2151 | Embeddings Left: 188\n",
      "Total loss 0.13809 | Reg loss 0.13794\n",
      "Epoch 024: |  Loss: 0.00033 | Acc: 1.000 | Val ACC: 0.912 | Features Left: 2147 | Embeddings Left: 188\n",
      "Total loss 0.13804 | Reg loss 0.13791\n",
      "Epoch 025: |  Loss: 0.00030 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2142 | Embeddings Left: 188\n",
      "Total loss 0.13800 | Reg loss 0.13788\n",
      "Epoch 026: |  Loss: 0.00028 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2138 | Embeddings Left: 188\n",
      "Total loss 0.13795 | Reg loss 0.13785\n",
      "Epoch 027: |  Loss: 0.00025 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2132 | Embeddings Left: 188\n",
      "Total loss 0.13790 | Reg loss 0.13781\n",
      "Epoch 028: |  Loss: 0.00024 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2126 | Embeddings Left: 188\n",
      "Total loss 0.13786 | Reg loss 0.13778\n",
      "Epoch 029: |  Loss: 0.00022 | Acc: 1.000 | Val ACC: 0.910 | Features Left: 2121 | Embeddings Left: 188\n",
      "Total loss 0.13781 | Reg loss 0.13774\n",
      "Epoch 030: |  Loss: 0.00020 | Acc: 1.000 | Val ACC: 0.907 | Features Left: 2119 | Embeddings Left: 188\n",
      "Total loss 0.13777 | Reg loss 0.13770\n",
      "Epoch 031: |  Loss: 0.00019 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2118 | Embeddings Left: 188\n",
      "Total loss 0.13773 | Reg loss 0.13766\n",
      "Epoch 032: |  Loss: 0.00018 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2115 | Embeddings Left: 188\n",
      "Total loss 0.13768 | Reg loss 0.13763\n",
      "Epoch 033: |  Loss: 0.00017 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2114 | Embeddings Left: 188\n",
      "Total loss 0.13764 | Reg loss 0.13759\n",
      "Epoch 034: |  Loss: 0.00016 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2112 | Embeddings Left: 188\n",
      "Total loss 0.13760 | Reg loss 0.13755\n",
      "Epoch 035: |  Loss: 0.00015 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2108 | Embeddings Left: 188\n",
      "Total loss 0.13755 | Reg loss 0.13751\n",
      "Epoch 036: |  Loss: 0.00014 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2104 | Embeddings Left: 188\n",
      "Total loss 0.13751 | Reg loss 0.13746\n",
      "Epoch 037: |  Loss: 0.00014 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2098 | Embeddings Left: 188\n",
      "Total loss 0.13746 | Reg loss 0.13742\n",
      "Epoch 038: |  Loss: 0.00013 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2097 | Embeddings Left: 188\n",
      "Total loss 0.13742 | Reg loss 0.13738\n",
      "Epoch 039: |  Loss: 0.00012 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2095 | Embeddings Left: 188\n",
      "Total loss 0.13737 | Reg loss 0.13734\n",
      "Epoch 040: |  Loss: 0.00012 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2091 | Embeddings Left: 188\n",
      "Total loss 0.13733 | Reg loss 0.13729\n",
      "Epoch 041: |  Loss: 0.00011 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2090 | Embeddings Left: 188\n",
      "Total loss 0.13728 | Reg loss 0.13725\n",
      "Epoch 042: |  Loss: 0.00011 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2090 | Embeddings Left: 188\n",
      "Total loss 0.13723 | Reg loss 0.13720\n",
      "Epoch 043: |  Loss: 0.00010 | Acc: 1.000 | Val ACC: 0.905 | Features Left: 2088 | Embeddings Left: 188\n",
      "Total loss 0.13718 | Reg loss 0.13716\n",
      "Epoch 044: |  Loss: 0.00010 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2084 | Embeddings Left: 188\n",
      "Total loss 0.13714 | Reg loss 0.13711\n",
      "Epoch 045: |  Loss: 0.00010 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2082 | Embeddings Left: 188\n",
      "Total loss 0.13709 | Reg loss 0.13706\n",
      "Epoch 046: |  Loss: 0.00009 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2081 | Embeddings Left: 188\n",
      "Total loss 0.13704 | Reg loss 0.13702\n",
      "Epoch 047: |  Loss: 0.00009 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2075 | Embeddings Left: 188\n",
      "Total loss 0.13699 | Reg loss 0.13697\n",
      "Epoch 048: |  Loss: 0.00009 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2073 | Embeddings Left: 188\n",
      "Total loss 0.13694 | Reg loss 0.13692\n",
      "Epoch 049: |  Loss: 0.00008 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2071 | Embeddings Left: 188\n",
      "Total loss 0.13689 | Reg loss 0.13687\n",
      "Epoch 050: |  Loss: 0.00008 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2070 | Embeddings Left: 188\n",
      "Total loss 0.13684 | Reg loss 0.13682\n",
      "Epoch 051: |  Loss: 0.00008 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2070 | Embeddings Left: 188\n",
      "Total loss 0.13679 | Reg loss 0.13677\n",
      "Epoch 052: |  Loss: 0.00008 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2068 | Embeddings Left: 188\n",
      "Total loss 0.13674 | Reg loss 0.13672\n",
      "Epoch 053: |  Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2066 | Embeddings Left: 188\n",
      "Total loss 0.13668 | Reg loss 0.13667\n",
      "Epoch 054: |  Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2062 | Embeddings Left: 188\n",
      "Total loss 0.13663 | Reg loss 0.13661\n",
      "Epoch 055: |  Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.902 | Features Left: 2060 | Embeddings Left: 188\n",
      "Total loss 0.13658 | Reg loss 0.13656\n",
      "Epoch 056: |  Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 2058 | Embeddings Left: 188\n",
      "Total loss 0.13652 | Reg loss 0.13651\n",
      "Epoch 057: |  Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 2053 | Embeddings Left: 188\n",
      "Total loss 0.13647 | Reg loss 0.13645\n",
      "Epoch 058: |  Loss: 0.00007 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 2053 | Embeddings Left: 188\n",
      "Total loss 0.13641 | Reg loss 0.13640\n",
      "Epoch 059: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2052 | Embeddings Left: 188\n",
      "Total loss 0.13636 | Reg loss 0.13634\n",
      "Epoch 060: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2050 | Embeddings Left: 188\n",
      "Total loss 0.13630 | Reg loss 0.13629\n",
      "Epoch 061: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2047 | Embeddings Left: 188\n",
      "Total loss 0.13625 | Reg loss 0.13623\n",
      "Epoch 062: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2046 | Embeddings Left: 188\n",
      "Total loss 0.13619 | Reg loss 0.13618\n",
      "Epoch 063: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2044 | Embeddings Left: 188\n",
      "Total loss 0.13613 | Reg loss 0.13612\n",
      "Epoch 064: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2039 | Embeddings Left: 188\n",
      "Total loss 0.13608 | Reg loss 0.13606\n",
      "Epoch 065: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2039 | Embeddings Left: 188\n",
      "Total loss 0.13602 | Reg loss 0.13601\n",
      "Epoch 066: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2036 | Embeddings Left: 188\n",
      "Total loss 0.13596 | Reg loss 0.13595\n",
      "Epoch 067: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2032 | Embeddings Left: 188\n",
      "Total loss 0.13590 | Reg loss 0.13589\n",
      "Epoch 068: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2030 | Embeddings Left: 188\n",
      "Total loss 0.13584 | Reg loss 0.13583\n",
      "Epoch 069: |  Loss: 0.00006 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2029 | Embeddings Left: 188\n",
      "Total loss 0.13578 | Reg loss 0.13577\n",
      "Epoch 070: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2027 | Embeddings Left: 188\n",
      "Total loss 0.13572 | Reg loss 0.13571\n",
      "Epoch 071: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2025 | Embeddings Left: 188\n",
      "Total loss 0.13566 | Reg loss 0.13565\n",
      "Epoch 072: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2022 | Embeddings Left: 188\n",
      "Total loss 0.13560 | Reg loss 0.13559\n",
      "Epoch 073: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2021 | Embeddings Left: 188\n",
      "Total loss 0.13554 | Reg loss 0.13553\n",
      "Epoch 074: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2018 | Embeddings Left: 188\n",
      "Total loss 0.13548 | Reg loss 0.13547\n",
      "Epoch 075: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2017 | Embeddings Left: 188\n",
      "Total loss 0.13542 | Reg loss 0.13540\n",
      "Epoch 076: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2015 | Embeddings Left: 188\n",
      "Total loss 0.13535 | Reg loss 0.13534\n",
      "Epoch 077: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2013 | Embeddings Left: 188\n",
      "Total loss 0.13529 | Reg loss 0.13528\n",
      "Epoch 078: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2010 | Embeddings Left: 188\n",
      "Total loss 0.13523 | Reg loss 0.13522\n",
      "Epoch 079: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2009 | Embeddings Left: 188\n",
      "Total loss 0.13516 | Reg loss 0.13515\n",
      "Epoch 080: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2007 | Embeddings Left: 188\n",
      "Total loss 0.13510 | Reg loss 0.13509\n",
      "Epoch 081: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2005 | Embeddings Left: 188\n",
      "Total loss 0.13503 | Reg loss 0.13502\n",
      "Epoch 082: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2001 | Embeddings Left: 188\n",
      "Total loss 0.13497 | Reg loss 0.13496\n",
      "Epoch 083: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 2001 | Embeddings Left: 188\n",
      "Total loss 0.13491 | Reg loss 0.13489\n",
      "Epoch 084: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 2001 | Embeddings Left: 188\n",
      "Total loss 0.13484 | Reg loss 0.13483\n",
      "Epoch 085: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 2001 | Embeddings Left: 188\n",
      "Total loss 0.13477 | Reg loss 0.13476\n",
      "Epoch 086: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 1999 | Embeddings Left: 188\n",
      "Total loss 0.13471 | Reg loss 0.13470\n",
      "Epoch 087: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 1996 | Embeddings Left: 188\n",
      "Total loss 0.13464 | Reg loss 0.13463\n",
      "Epoch 088: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 1996 | Embeddings Left: 188\n",
      "Total loss 0.13458 | Reg loss 0.13456\n",
      "Epoch 089: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 1994 | Embeddings Left: 188\n",
      "Total loss 0.13451 | Reg loss 0.13450\n",
      "Epoch 090: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 1993 | Embeddings Left: 188\n",
      "Total loss 0.13444 | Reg loss 0.13443\n",
      "Epoch 091: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 1992 | Embeddings Left: 188\n",
      "Total loss 0.13437 | Reg loss 0.13436\n",
      "Epoch 092: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.900 | Features Left: 1990 | Embeddings Left: 188\n",
      "Total loss 0.13431 | Reg loss 0.13429\n",
      "Epoch 093: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 1989 | Embeddings Left: 188\n",
      "Total loss 0.13424 | Reg loss 0.13423\n",
      "Epoch 094: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 1987 | Embeddings Left: 188\n",
      "Total loss 0.13417 | Reg loss 0.13416\n",
      "Epoch 095: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 1986 | Embeddings Left: 188\n",
      "Total loss 0.13410 | Reg loss 0.13409\n",
      "Epoch 096: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 1986 | Embeddings Left: 188\n",
      "Total loss 0.13403 | Reg loss 0.13402\n",
      "Epoch 097: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 1983 | Embeddings Left: 188\n",
      "Total loss 0.13396 | Reg loss 0.13395\n",
      "Epoch 098: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 1983 | Embeddings Left: 188\n",
      "Total loss 0.13389 | Reg loss 0.13388\n",
      "Epoch 099: |  Loss: 0.00005 | Acc: 1.000 | Val ACC: 0.897 | Features Left: 1981 | Embeddings Left: 188\n",
      "Total loss 0.13382 | Reg loss 0.13381\n",
      "Client 0: Feature Index 0-972\n",
      "Client 1: Feature Index 973-1945\n",
      "Client 2: Feature Index 1946-2917\n",
      "Client 3: Feature Index 2918-3889\n",
      "Server : Feature Index 3890-4861\n",
      "Training Starts\n",
      "Number of Clients: 4\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: |  Loss: 0.69235 | Acc: 0.547 | Val ACC: 0.797 | Features Left: 2117 | Embeddings Left: 267\n",
      "Total loss 0.82381 | Reg loss 0.13815\n",
      "Epoch 001: |  Loss: 0.59146 | Acc: 0.873 | Val ACC: 0.882 | Features Left: 2130 | Embeddings Left: 267\n",
      "Total loss 0.55453 | Reg loss 0.13818\n",
      "Epoch 002: |  Loss: 0.21858 | Acc: 0.924 | Val ACC: 0.907 | Features Left: 2235 | Embeddings Left: 267\n",
      "Total loss 0.26731 | Reg loss 0.13829\n",
      "Epoch 003: |  Loss: 0.10506 | Acc: 0.953 | Val ACC: 0.870 | Features Left: 2279 | Embeddings Left: 267\n",
      "Total loss 0.21175 | Reg loss 0.13832\n",
      "Epoch 004: |  Loss: 0.12017 | Acc: 0.953 | Val ACC: 0.882 | Features Left: 2292 | Embeddings Left: 267\n",
      "Total loss 0.16673 | Reg loss 0.13829\n",
      "Epoch 005: |  Loss: 0.09889 | Acc: 0.954 | Val ACC: 0.872 | Features Left: 2313 | Embeddings Left: 267\n",
      "Total loss 0.19632 | Reg loss 0.13826\n",
      "Epoch 006: |  Loss: 0.05058 | Acc: 0.981 | Val ACC: 0.915 | Features Left: 2321 | Embeddings Left: 267\n",
      "Total loss 0.15651 | Reg loss 0.13826\n",
      "Epoch 007: |  Loss: 0.03477 | Acc: 0.987 | Val ACC: 0.920 | Features Left: 2333 | Embeddings Left: 267\n",
      "Total loss 0.14942 | Reg loss 0.13828\n",
      "Epoch 008: |  Loss: 0.02216 | Acc: 0.995 | Val ACC: 0.917 | Features Left: 2331 | Embeddings Left: 267\n",
      "Total loss 0.14494 | Reg loss 0.13829\n",
      "Epoch 009: |  Loss: 0.01547 | Acc: 0.996 | Val ACC: 0.915 | Features Left: 2325 | Embeddings Left: 267\n",
      "Total loss 0.14306 | Reg loss 0.13830\n",
      "Epoch 010: |  Loss: 0.01150 | Acc: 0.997 | Val ACC: 0.915 | Features Left: 2324 | Embeddings Left: 267\n",
      "Total loss 0.14153 | Reg loss 0.13831\n",
      "Epoch 011: |  Loss: 0.00925 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2324 | Embeddings Left: 267\n",
      "Total loss 0.14085 | Reg loss 0.13831\n",
      "Epoch 012: |  Loss: 0.00803 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2318 | Embeddings Left: 267\n",
      "Total loss 0.14019 | Reg loss 0.13831\n",
      "Epoch 013: |  Loss: 0.00702 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2314 | Embeddings Left: 267\n",
      "Total loss 0.13994 | Reg loss 0.13831\n",
      "Epoch 014: |  Loss: 0.00663 | Acc: 0.998 | Val ACC: 0.912 | Features Left: 2310 | Embeddings Left: 267\n",
      "Total loss 0.13960 | Reg loss 0.13830\n",
      "Epoch 015: |  Loss: 0.00607 | Acc: 0.998 | Val ACC: 0.912 | Features Left: 2307 | Embeddings Left: 267\n",
      "Total loss 0.13939 | Reg loss 0.13829\n",
      "Epoch 016: |  Loss: 0.00584 | Acc: 0.998 | Val ACC: 0.912 | Features Left: 2303 | Embeddings Left: 267\n",
      "Total loss 0.13923 | Reg loss 0.13828\n",
      "Epoch 017: |  Loss: 0.00554 | Acc: 0.998 | Val ACC: 0.912 | Features Left: 2301 | Embeddings Left: 267\n",
      "Total loss 0.13913 | Reg loss 0.13827\n",
      "Epoch 018: |  Loss: 0.00541 | Acc: 0.998 | Val ACC: 0.912 | Features Left: 2294 | Embeddings Left: 267\n",
      "Total loss 0.13897 | Reg loss 0.13826\n",
      "Epoch 019: |  Loss: 0.00520 | Acc: 0.998 | Val ACC: 0.912 | Features Left: 2293 | Embeddings Left: 267\n",
      "Total loss 0.13888 | Reg loss 0.13824\n",
      "Epoch 020: |  Loss: 0.00507 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2288 | Embeddings Left: 267\n",
      "Total loss 0.13880 | Reg loss 0.13823\n",
      "Epoch 021: |  Loss: 0.00496 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2287 | Embeddings Left: 267\n",
      "Total loss 0.13872 | Reg loss 0.13821\n",
      "Epoch 022: |  Loss: 0.00485 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2285 | Embeddings Left: 267\n",
      "Total loss 0.13866 | Reg loss 0.13820\n",
      "Epoch 023: |  Loss: 0.00474 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2283 | Embeddings Left: 267\n",
      "Total loss 0.13860 | Reg loss 0.13818\n",
      "Epoch 024: |  Loss: 0.00469 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2278 | Embeddings Left: 267\n",
      "Total loss 0.13854 | Reg loss 0.13816\n",
      "Epoch 025: |  Loss: 0.00455 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2275 | Embeddings Left: 267\n",
      "Total loss 0.13849 | Reg loss 0.13814\n",
      "Epoch 026: |  Loss: 0.00445 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2274 | Embeddings Left: 267\n",
      "Total loss 0.13844 | Reg loss 0.13812\n",
      "Epoch 027: |  Loss: 0.00434 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2273 | Embeddings Left: 267\n",
      "Total loss 0.13840 | Reg loss 0.13810\n",
      "Epoch 028: |  Loss: 0.00430 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2269 | Embeddings Left: 267\n",
      "Total loss 0.13835 | Reg loss 0.13808\n",
      "Epoch 029: |  Loss: 0.00420 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2268 | Embeddings Left: 267\n",
      "Total loss 0.13832 | Reg loss 0.13806\n",
      "Epoch 030: |  Loss: 0.00412 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2264 | Embeddings Left: 267\n",
      "Total loss 0.13828 | Reg loss 0.13804\n",
      "Epoch 031: |  Loss: 0.00398 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2262 | Embeddings Left: 267\n",
      "Total loss 0.13823 | Reg loss 0.13802\n",
      "Epoch 032: |  Loss: 0.00390 | Acc: 0.998 | Val ACC: 0.915 | Features Left: 2262 | Embeddings Left: 267\n",
      "Total loss 0.13819 | Reg loss 0.13800\n",
      "Epoch 033: |  Loss: 0.00380 | Acc: 0.999 | Val ACC: 0.912 | Features Left: 2261 | Embeddings Left: 267\n",
      "Total loss 0.13816 | Reg loss 0.13798\n",
      "Epoch 034: |  Loss: 0.00367 | Acc: 0.999 | Val ACC: 0.912 | Features Left: 2255 | Embeddings Left: 267\n",
      "Total loss 0.13812 | Reg loss 0.13796\n",
      "Epoch 035: |  Loss: 0.00369 | Acc: 0.999 | Val ACC: 0.912 | Features Left: 2253 | Embeddings Left: 267\n",
      "Total loss 0.13808 | Reg loss 0.13793\n",
      "Epoch 036: |  Loss: 0.00346 | Acc: 0.999 | Val ACC: 0.912 | Features Left: 2252 | Embeddings Left: 267\n",
      "Total loss 0.13806 | Reg loss 0.13791\n",
      "Epoch 037: |  Loss: 0.00337 | Acc: 0.999 | Val ACC: 0.912 | Features Left: 2250 | Embeddings Left: 267\n",
      "Total loss 0.13803 | Reg loss 0.13789\n",
      "Epoch 038: |  Loss: 0.00330 | Acc: 0.999 | Val ACC: 0.912 | Features Left: 2247 | Embeddings Left: 267\n",
      "Total loss 0.13799 | Reg loss 0.13786\n",
      "Epoch 039: |  Loss: 0.00315 | Acc: 0.999 | Val ACC: 0.912 | Features Left: 2243 | Embeddings Left: 267\n",
      "Total loss 0.13797 | Reg loss 0.13784\n",
      "Epoch 040: |  Loss: 0.00307 | Acc: 0.999 | Val ACC: 0.912 | Features Left: 2239 | Embeddings Left: 267\n",
      "Total loss 0.13793 | Reg loss 0.13782\n",
      "Epoch 041: |  Loss: 0.00305 | Acc: 0.999 | Val ACC: 0.912 | Features Left: 2238 | Embeddings Left: 267\n",
      "Total loss 0.13790 | Reg loss 0.13779\n",
      "Epoch 042: |  Loss: 0.00285 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2236 | Embeddings Left: 267\n",
      "Total loss 0.13787 | Reg loss 0.13777\n",
      "Epoch 043: |  Loss: 0.00282 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2236 | Embeddings Left: 267\n",
      "Total loss 0.13783 | Reg loss 0.13774\n",
      "Epoch 044: |  Loss: 0.00268 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2234 | Embeddings Left: 267\n",
      "Total loss 0.13780 | Reg loss 0.13772\n",
      "Epoch 045: |  Loss: 0.00264 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2230 | Embeddings Left: 267\n",
      "Total loss 0.13778 | Reg loss 0.13769\n",
      "Epoch 046: |  Loss: 0.00249 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2230 | Embeddings Left: 267\n",
      "Total loss 0.13774 | Reg loss 0.13766\n",
      "Epoch 047: |  Loss: 0.00248 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2228 | Embeddings Left: 267\n",
      "Total loss 0.13771 | Reg loss 0.13764\n",
      "Epoch 048: |  Loss: 0.00234 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2227 | Embeddings Left: 267\n",
      "Total loss 0.13768 | Reg loss 0.13761\n",
      "Epoch 049: |  Loss: 0.00237 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2227 | Embeddings Left: 267\n",
      "Total loss 0.13765 | Reg loss 0.13758\n",
      "Epoch 050: |  Loss: 0.00220 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2225 | Embeddings Left: 267\n",
      "Total loss 0.13761 | Reg loss 0.13756\n",
      "Epoch 051: |  Loss: 0.00224 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2225 | Embeddings Left: 267\n",
      "Total loss 0.13758 | Reg loss 0.13753\n",
      "Epoch 052: |  Loss: 0.00208 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2223 | Embeddings Left: 267\n",
      "Total loss 0.13755 | Reg loss 0.13750\n",
      "Epoch 053: |  Loss: 0.00218 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2222 | Embeddings Left: 267\n",
      "Total loss 0.13752 | Reg loss 0.13747\n",
      "Epoch 054: |  Loss: 0.00202 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2221 | Embeddings Left: 267\n",
      "Total loss 0.13749 | Reg loss 0.13744\n",
      "Epoch 055: |  Loss: 0.00214 | Acc: 0.999 | Val ACC: 0.907 | Features Left: 2220 | Embeddings Left: 267\n",
      "Total loss 0.13746 | Reg loss 0.13741\n",
      "Epoch 056: |  Loss: 0.00191 | Acc: 0.999 | Val ACC: 0.907 | Features Left: 2216 | Embeddings Left: 267\n",
      "Total loss 0.13743 | Reg loss 0.13738\n",
      "Epoch 057: |  Loss: 0.00216 | Acc: 0.999 | Val ACC: 0.907 | Features Left: 2215 | Embeddings Left: 267\n",
      "Total loss 0.13739 | Reg loss 0.13735\n",
      "Epoch 058: |  Loss: 0.00180 | Acc: 0.999 | Val ACC: 0.905 | Features Left: 2213 | Embeddings Left: 267\n",
      "Total loss 0.13736 | Reg loss 0.13732\n",
      "Epoch 059: |  Loss: 0.00237 | Acc: 0.999 | Val ACC: 0.907 | Features Left: 2211 | Embeddings Left: 267\n",
      "Total loss 0.13732 | Reg loss 0.13729\n",
      "Epoch 060: |  Loss: 0.00172 | Acc: 0.999 | Val ACC: 0.905 | Features Left: 2210 | Embeddings Left: 267\n",
      "Total loss 0.13730 | Reg loss 0.13726\n",
      "Epoch 061: |  Loss: 0.00323 | Acc: 0.999 | Val ACC: 0.905 | Features Left: 2209 | Embeddings Left: 267\n",
      "Total loss 0.13725 | Reg loss 0.13722\n",
      "Epoch 062: |  Loss: 0.00192 | Acc: 0.999 | Val ACC: 0.905 | Features Left: 2206 | Embeddings Left: 267\n",
      "Total loss 0.13724 | Reg loss 0.13719\n",
      "Epoch 063: |  Loss: 0.00456 | Acc: 0.998 | Val ACC: 0.905 | Features Left: 2204 | Embeddings Left: 267\n",
      "Total loss 0.13718 | Reg loss 0.13716\n",
      "Epoch 064: |  Loss: 0.00240 | Acc: 0.999 | Val ACC: 0.910 | Features Left: 2202 | Embeddings Left: 267\n",
      "Total loss 0.13718 | Reg loss 0.13712\n",
      "Epoch 065: |  Loss: 0.00415 | Acc: 0.998 | Val ACC: 0.902 | Features Left: 2199 | Embeddings Left: 267\n",
      "Total loss 0.13714 | Reg loss 0.13708\n",
      "Epoch 066: |  Loss: 0.16668 | Acc: 0.990 | Val ACC: 0.872 | Features Left: 2194 | Embeddings Left: 267\n",
      "Total loss 0.20489 | Reg loss 0.13701\n",
      "Epoch 067: |  Loss: 0.22971 | Acc: 0.973 | Val ACC: 0.870 | Features Left: 2209 | Embeddings Left: 267\n",
      "Total loss 0.20963 | Reg loss 0.13681\n",
      "Epoch 068: |  Loss: 0.09495 | Acc: 0.969 | Val ACC: 0.882 | Features Left: 2224 | Embeddings Left: 267\n",
      "Total loss 0.17046 | Reg loss 0.13662\n",
      "Epoch 069: |  Loss: 0.07452 | Acc: 0.979 | Val ACC: 0.890 | Features Left: 2244 | Embeddings Left: 267\n",
      "Total loss 0.15740 | Reg loss 0.13658\n",
      "Epoch 070: |  Loss: 0.02814 | Acc: 0.992 | Val ACC: 0.897 | Features Left: 2268 | Embeddings Left: 267\n",
      "Total loss 0.14518 | Reg loss 0.13662\n",
      "Epoch 071: |  Loss: 0.00975 | Acc: 0.996 | Val ACC: 0.897 | Features Left: 2272 | Embeddings Left: 267\n",
      "Total loss 0.14105 | Reg loss 0.13665\n",
      "Epoch 072: |  Loss: 0.00631 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2274 | Embeddings Left: 267\n",
      "Total loss 0.13961 | Reg loss 0.13666\n",
      "Epoch 073: |  Loss: 0.00439 | Acc: 0.999 | Val ACC: 0.897 | Features Left: 2276 | Embeddings Left: 267\n",
      "Total loss 0.13857 | Reg loss 0.13665\n",
      "Epoch 074: |  Loss: 0.00357 | Acc: 0.999 | Val ACC: 0.897 | Features Left: 2274 | Embeddings Left: 267\n",
      "Total loss 0.13802 | Reg loss 0.13664\n",
      "Epoch 075: |  Loss: 0.00319 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2273 | Embeddings Left: 267\n",
      "Total loss 0.13763 | Reg loss 0.13663\n",
      "Epoch 076: |  Loss: 0.00281 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2270 | Embeddings Left: 267\n",
      "Total loss 0.13742 | Reg loss 0.13661\n",
      "Epoch 077: |  Loss: 0.00266 | Acc: 0.999 | Val ACC: 0.902 | Features Left: 2268 | Embeddings Left: 267\n",
      "Total loss 0.13722 | Reg loss 0.13659\n",
      "Epoch 078: |  Loss: 0.00240 | Acc: 0.999 | Val ACC: 0.902 | Features Left: 2267 | Embeddings Left: 267\n",
      "Total loss 0.13709 | Reg loss 0.13657\n",
      "Epoch 079: |  Loss: 0.00231 | Acc: 0.999 | Val ACC: 0.902 | Features Left: 2266 | Embeddings Left: 267\n",
      "Total loss 0.13696 | Reg loss 0.13655\n",
      "Epoch 080: |  Loss: 0.00214 | Acc: 0.999 | Val ACC: 0.902 | Features Left: 2266 | Embeddings Left: 267\n",
      "Total loss 0.13690 | Reg loss 0.13653\n",
      "Epoch 081: |  Loss: 0.00206 | Acc: 0.999 | Val ACC: 0.902 | Features Left: 2266 | Embeddings Left: 267\n",
      "Total loss 0.13683 | Reg loss 0.13651\n",
      "Epoch 082: |  Loss: 0.00203 | Acc: 0.999 | Val ACC: 0.902 | Features Left: 2264 | Embeddings Left: 267\n",
      "Total loss 0.13676 | Reg loss 0.13649\n",
      "Epoch 083: |  Loss: 0.00189 | Acc: 0.999 | Val ACC: 0.902 | Features Left: 2264 | Embeddings Left: 267\n",
      "Total loss 0.13671 | Reg loss 0.13647\n",
      "Epoch 084: |  Loss: 0.00189 | Acc: 0.999 | Val ACC: 0.902 | Features Left: 2264 | Embeddings Left: 267\n",
      "Total loss 0.13664 | Reg loss 0.13644\n",
      "Epoch 085: |  Loss: 0.00179 | Acc: 0.999 | Val ACC: 0.902 | Features Left: 2263 | Embeddings Left: 267\n",
      "Total loss 0.13661 | Reg loss 0.13642\n",
      "Epoch 086: |  Loss: 0.00180 | Acc: 0.999 | Val ACC: 0.902 | Features Left: 2263 | Embeddings Left: 267\n",
      "Total loss 0.13657 | Reg loss 0.13639\n",
      "Epoch 087: |  Loss: 0.00179 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2263 | Embeddings Left: 267\n",
      "Total loss 0.13652 | Reg loss 0.13637\n",
      "Epoch 088: |  Loss: 0.00173 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2262 | Embeddings Left: 267\n",
      "Total loss 0.13649 | Reg loss 0.13634\n",
      "Epoch 089: |  Loss: 0.00170 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2261 | Embeddings Left: 267\n",
      "Total loss 0.13645 | Reg loss 0.13632\n",
      "Epoch 090: |  Loss: 0.00167 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2260 | Embeddings Left: 267\n",
      "Total loss 0.13641 | Reg loss 0.13629\n",
      "Epoch 091: |  Loss: 0.00168 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2260 | Embeddings Left: 267\n",
      "Total loss 0.13638 | Reg loss 0.13627\n",
      "Epoch 092: |  Loss: 0.00165 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2260 | Embeddings Left: 267\n",
      "Total loss 0.13633 | Reg loss 0.13624\n",
      "Epoch 093: |  Loss: 0.00162 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2256 | Embeddings Left: 267\n",
      "Total loss 0.13631 | Reg loss 0.13622\n",
      "Epoch 094: |  Loss: 0.00165 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2254 | Embeddings Left: 267\n",
      "Total loss 0.13627 | Reg loss 0.13619\n",
      "Epoch 095: |  Loss: 0.00158 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2252 | Embeddings Left: 267\n",
      "Total loss 0.13624 | Reg loss 0.13616\n",
      "Epoch 096: |  Loss: 0.00166 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2250 | Embeddings Left: 267\n",
      "Total loss 0.13621 | Reg loss 0.13613\n",
      "Epoch 097: |  Loss: 0.00150 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2250 | Embeddings Left: 267\n",
      "Total loss 0.13618 | Reg loss 0.13611\n",
      "Epoch 098: |  Loss: 0.00169 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2249 | Embeddings Left: 267\n",
      "Total loss 0.13614 | Reg loss 0.13608\n",
      "Epoch 099: |  Loss: 0.00140 | Acc: 0.999 | Val ACC: 0.900 | Features Left: 2249 | Embeddings Left: 267\n",
      "Total loss 0.13612 | Reg loss 0.13605\n",
      "Client 0: Feature Index 0-810\n",
      "Client 1: Feature Index 811-1621\n",
      "Client 2: Feature Index 1622-2431\n",
      "Client 3: Feature Index 2432-3241\n",
      "Client 4: Feature Index 3242-4051\n",
      "Server : Feature Index 4052-4861\n",
      "Training Starts\n",
      "Number of Clients: 5\n",
      "-----------------------------------------------------------------------------------------\n",
      "Epoch 000: |  Loss: 0.69327 | Acc: 0.499 | Val ACC: 0.526 | Features Left: 2124 | Embeddings Left: 325\n",
      "Total loss 0.82536 | Reg loss 0.13815\n",
      "Epoch 001: |  Loss: 0.60337 | Acc: 0.744 | Val ACC: 0.850 | Features Left: 2139 | Embeddings Left: 325\n",
      "Total loss 0.59800 | Reg loss 0.13817\n",
      "Epoch 002: |  Loss: 0.25502 | Acc: 0.906 | Val ACC: 0.860 | Features Left: 2233 | Embeddings Left: 325\n",
      "Total loss 0.32864 | Reg loss 0.13828\n",
      "Epoch 003: |  Loss: 0.12771 | Acc: 0.947 | Val ACC: 0.860 | Features Left: 2274 | Embeddings Left: 325\n",
      "Total loss 0.22007 | Reg loss 0.13829\n",
      "Epoch 004: |  Loss: 0.11205 | Acc: 0.951 | Val ACC: 0.840 | Features Left: 2303 | Embeddings Left: 325\n",
      "Total loss 0.18731 | Reg loss 0.13828\n",
      "Epoch 005: |  Loss: 0.14272 | Acc: 0.938 | Val ACC: 0.867 | Features Left: 2319 | Embeddings Left: 325\n",
      "Total loss 0.30574 | Reg loss 0.13826\n",
      "Epoch 006: |  Loss: 0.07384 | Acc: 0.971 | Val ACC: 0.875 | Features Left: 2345 | Embeddings Left: 325\n",
      "Total loss 0.19712 | Reg loss 0.13826\n",
      "Epoch 007: |  Loss: 0.04907 | Acc: 0.984 | Val ACC: 0.882 | Features Left: 2352 | Embeddings Left: 325\n",
      "Total loss 0.17257 | Reg loss 0.13828\n",
      "Epoch 008: |  Loss: 0.03908 | Acc: 0.985 | Val ACC: 0.887 | Features Left: 2356 | Embeddings Left: 325\n",
      "Total loss 0.16749 | Reg loss 0.13829\n",
      "Epoch 009: |  Loss: 0.02503 | Acc: 0.992 | Val ACC: 0.890 | Features Left: 2353 | Embeddings Left: 325\n",
      "Total loss 0.14955 | Reg loss 0.13831\n",
      "Epoch 010: |  Loss: 0.01941 | Acc: 0.995 | Val ACC: 0.892 | Features Left: 2352 | Embeddings Left: 325\n",
      "Total loss 0.14559 | Reg loss 0.13832\n",
      "Epoch 011: |  Loss: 0.01414 | Acc: 0.996 | Val ACC: 0.892 | Features Left: 2352 | Embeddings Left: 325\n",
      "Total loss 0.14299 | Reg loss 0.13833\n",
      "Epoch 012: |  Loss: 0.01125 | Acc: 0.997 | Val ACC: 0.897 | Features Left: 2348 | Embeddings Left: 325\n",
      "Total loss 0.14159 | Reg loss 0.13833\n",
      "Epoch 013: |  Loss: 0.00989 | Acc: 0.997 | Val ACC: 0.895 | Features Left: 2346 | Embeddings Left: 325\n",
      "Total loss 0.14087 | Reg loss 0.13833\n",
      "Epoch 014: |  Loss: 0.00876 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2345 | Embeddings Left: 325\n",
      "Total loss 0.14025 | Reg loss 0.13833\n",
      "Epoch 015: |  Loss: 0.00794 | Acc: 0.998 | Val ACC: 0.900 | Features Left: 2340 | Embeddings Left: 325\n",
      "Total loss 0.13985 | Reg loss 0.13833\n",
      "Epoch 016: |  Loss: 0.00759 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2339 | Embeddings Left: 325\n",
      "Total loss 0.13959 | Reg loss 0.13832\n",
      "Epoch 017: |  Loss: 0.00731 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2336 | Embeddings Left: 325\n",
      "Total loss 0.13939 | Reg loss 0.13832\n",
      "Epoch 018: |  Loss: 0.00722 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2330 | Embeddings Left: 325\n",
      "Total loss 0.13922 | Reg loss 0.13831\n",
      "Epoch 019: |  Loss: 0.00686 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2326 | Embeddings Left: 325\n",
      "Total loss 0.13909 | Reg loss 0.13830\n",
      "Epoch 020: |  Loss: 0.00654 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2324 | Embeddings Left: 325\n",
      "Total loss 0.13895 | Reg loss 0.13829\n",
      "Epoch 021: |  Loss: 0.00642 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2321 | Embeddings Left: 325\n",
      "Total loss 0.13888 | Reg loss 0.13828\n",
      "Epoch 022: |  Loss: 0.00619 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2319 | Embeddings Left: 325\n",
      "Total loss 0.13879 | Reg loss 0.13827\n",
      "Epoch 023: |  Loss: 0.00598 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2315 | Embeddings Left: 325\n",
      "Total loss 0.13872 | Reg loss 0.13826\n",
      "Epoch 024: |  Loss: 0.00577 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2307 | Embeddings Left: 325\n",
      "Total loss 0.13865 | Reg loss 0.13825\n",
      "Epoch 025: |  Loss: 0.00562 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2305 | Embeddings Left: 325\n",
      "Total loss 0.13858 | Reg loss 0.13824\n",
      "Epoch 026: |  Loss: 0.00551 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2303 | Embeddings Left: 325\n",
      "Total loss 0.13854 | Reg loss 0.13822\n",
      "Epoch 027: |  Loss: 0.00524 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2301 | Embeddings Left: 325\n",
      "Total loss 0.13849 | Reg loss 0.13821\n",
      "Epoch 028: |  Loss: 0.00508 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2298 | Embeddings Left: 325\n",
      "Total loss 0.13845 | Reg loss 0.13820\n",
      "Epoch 029: |  Loss: 0.00492 | Acc: 0.999 | Val ACC: 0.895 | Features Left: 2296 | Embeddings Left: 325\n",
      "Total loss 0.13842 | Reg loss 0.13818\n",
      "Epoch 030: |  Loss: 0.00480 | Acc: 0.999 | Val ACC: 0.895 | Features Left: 2294 | Embeddings Left: 325\n",
      "Total loss 0.13838 | Reg loss 0.13817\n",
      "Epoch 031: |  Loss: 0.00464 | Acc: 0.999 | Val ACC: 0.895 | Features Left: 2291 | Embeddings Left: 325\n",
      "Total loss 0.13835 | Reg loss 0.13816\n",
      "Epoch 032: |  Loss: 0.00447 | Acc: 0.999 | Val ACC: 0.895 | Features Left: 2286 | Embeddings Left: 325\n",
      "Total loss 0.13831 | Reg loss 0.13814\n",
      "Epoch 033: |  Loss: 0.00432 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2284 | Embeddings Left: 325\n",
      "Total loss 0.13829 | Reg loss 0.13813\n",
      "Epoch 034: |  Loss: 0.00425 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2281 | Embeddings Left: 325\n",
      "Total loss 0.13826 | Reg loss 0.13811\n",
      "Epoch 035: |  Loss: 0.00421 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2280 | Embeddings Left: 325\n",
      "Total loss 0.13824 | Reg loss 0.13810\n",
      "Epoch 036: |  Loss: 0.00405 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2278 | Embeddings Left: 325\n",
      "Total loss 0.13821 | Reg loss 0.13808\n",
      "Epoch 037: |  Loss: 0.00392 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2278 | Embeddings Left: 325\n",
      "Total loss 0.13818 | Reg loss 0.13807\n",
      "Epoch 038: |  Loss: 0.00385 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2277 | Embeddings Left: 325\n",
      "Total loss 0.13816 | Reg loss 0.13805\n",
      "Epoch 039: |  Loss: 0.00380 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2276 | Embeddings Left: 325\n",
      "Total loss 0.13813 | Reg loss 0.13803\n",
      "Epoch 040: |  Loss: 0.00373 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2273 | Embeddings Left: 325\n",
      "Total loss 0.13811 | Reg loss 0.13801\n",
      "Epoch 041: |  Loss: 0.00367 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2271 | Embeddings Left: 325\n",
      "Total loss 0.13809 | Reg loss 0.13800\n",
      "Epoch 042: |  Loss: 0.00364 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2269 | Embeddings Left: 325\n",
      "Total loss 0.13807 | Reg loss 0.13798\n",
      "Epoch 043: |  Loss: 0.00367 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2267 | Embeddings Left: 325\n",
      "Total loss 0.13804 | Reg loss 0.13796\n",
      "Epoch 044: |  Loss: 0.00361 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2264 | Embeddings Left: 325\n",
      "Total loss 0.13802 | Reg loss 0.13794\n",
      "Epoch 045: |  Loss: 0.00358 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2261 | Embeddings Left: 325\n",
      "Total loss 0.13800 | Reg loss 0.13792\n",
      "Epoch 046: |  Loss: 0.00353 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2260 | Embeddings Left: 325\n",
      "Total loss 0.13798 | Reg loss 0.13790\n",
      "Epoch 047: |  Loss: 0.00352 | Acc: 0.998 | Val ACC: 0.900 | Features Left: 2259 | Embeddings Left: 325\n",
      "Total loss 0.13796 | Reg loss 0.13788\n",
      "Epoch 048: |  Loss: 0.00352 | Acc: 0.998 | Val ACC: 0.900 | Features Left: 2258 | Embeddings Left: 325\n",
      "Total loss 0.13793 | Reg loss 0.13786\n",
      "Epoch 049: |  Loss: 0.00346 | Acc: 0.998 | Val ACC: 0.900 | Features Left: 2253 | Embeddings Left: 325\n",
      "Total loss 0.13791 | Reg loss 0.13784\n",
      "Epoch 050: |  Loss: 0.00350 | Acc: 0.998 | Val ACC: 0.900 | Features Left: 2251 | Embeddings Left: 325\n",
      "Total loss 0.13789 | Reg loss 0.13782\n",
      "Epoch 051: |  Loss: 0.00353 | Acc: 0.998 | Val ACC: 0.900 | Features Left: 2248 | Embeddings Left: 325\n",
      "Total loss 0.13787 | Reg loss 0.13779\n",
      "Epoch 052: |  Loss: 0.00342 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2243 | Embeddings Left: 325\n",
      "Total loss 0.13784 | Reg loss 0.13777\n",
      "Epoch 053: |  Loss: 0.00343 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2243 | Embeddings Left: 325\n",
      "Total loss 0.13782 | Reg loss 0.13775\n",
      "Epoch 054: |  Loss: 0.00341 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2242 | Embeddings Left: 325\n",
      "Total loss 0.13779 | Reg loss 0.13773\n",
      "Epoch 055: |  Loss: 0.00333 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2242 | Embeddings Left: 325\n",
      "Total loss 0.13777 | Reg loss 0.13770\n",
      "Epoch 056: |  Loss: 0.00334 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2240 | Embeddings Left: 325\n",
      "Total loss 0.13774 | Reg loss 0.13768\n",
      "Epoch 057: |  Loss: 0.00340 | Acc: 0.998 | Val ACC: 0.897 | Features Left: 2239 | Embeddings Left: 325\n",
      "Total loss 0.13772 | Reg loss 0.13766\n",
      "Epoch 058: |  Loss: 0.00334 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2238 | Embeddings Left: 325\n",
      "Total loss 0.13770 | Reg loss 0.13763\n",
      "Epoch 059: |  Loss: 0.00331 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2237 | Embeddings Left: 325\n",
      "Total loss 0.13767 | Reg loss 0.13761\n",
      "Epoch 060: |  Loss: 0.00333 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2237 | Embeddings Left: 325\n",
      "Total loss 0.13764 | Reg loss 0.13758\n",
      "Epoch 061: |  Loss: 0.00330 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2236 | Embeddings Left: 325\n",
      "Total loss 0.13762 | Reg loss 0.13756\n",
      "Epoch 062: |  Loss: 0.00333 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2232 | Embeddings Left: 325\n",
      "Total loss 0.13760 | Reg loss 0.13753\n",
      "Epoch 063: |  Loss: 0.00326 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2232 | Embeddings Left: 325\n",
      "Total loss 0.13757 | Reg loss 0.13751\n",
      "Epoch 064: |  Loss: 0.00329 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2231 | Embeddings Left: 325\n",
      "Total loss 0.13755 | Reg loss 0.13748\n",
      "Epoch 065: |  Loss: 0.00321 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2230 | Embeddings Left: 325\n",
      "Total loss 0.13752 | Reg loss 0.13746\n",
      "Epoch 066: |  Loss: 0.00332 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2229 | Embeddings Left: 325\n",
      "Total loss 0.13749 | Reg loss 0.13743\n",
      "Epoch 067: |  Loss: 0.00317 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2229 | Embeddings Left: 325\n",
      "Total loss 0.13747 | Reg loss 0.13741\n",
      "Epoch 068: |  Loss: 0.00331 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2227 | Embeddings Left: 325\n",
      "Total loss 0.13744 | Reg loss 0.13738\n",
      "Epoch 069: |  Loss: 0.00320 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2227 | Embeddings Left: 325\n",
      "Total loss 0.13742 | Reg loss 0.13735\n",
      "Epoch 070: |  Loss: 0.00320 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2222 | Embeddings Left: 325\n",
      "Total loss 0.13738 | Reg loss 0.13733\n",
      "Epoch 071: |  Loss: 0.00319 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2220 | Embeddings Left: 325\n",
      "Total loss 0.13736 | Reg loss 0.13730\n",
      "Epoch 072: |  Loss: 0.00314 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2219 | Embeddings Left: 325\n",
      "Total loss 0.13734 | Reg loss 0.13727\n",
      "Epoch 073: |  Loss: 0.00319 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2219 | Embeddings Left: 325\n",
      "Total loss 0.13731 | Reg loss 0.13725\n",
      "Epoch 074: |  Loss: 0.00315 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2218 | Embeddings Left: 325\n",
      "Total loss 0.13728 | Reg loss 0.13722\n",
      "Epoch 075: |  Loss: 0.00315 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2218 | Embeddings Left: 325\n",
      "Total loss 0.13725 | Reg loss 0.13719\n",
      "Epoch 076: |  Loss: 0.00308 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2216 | Embeddings Left: 325\n",
      "Total loss 0.13722 | Reg loss 0.13716\n",
      "Epoch 077: |  Loss: 0.00325 | Acc: 0.998 | Val ACC: 0.895 | Features Left: 2213 | Embeddings Left: 325\n",
      "Total loss 0.13720 | Reg loss 0.13714\n",
      "Epoch 078: |  Loss: 0.00306 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2212 | Embeddings Left: 325\n",
      "Total loss 0.13717 | Reg loss 0.13711\n",
      "Epoch 079: |  Loss: 0.00319 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2210 | Embeddings Left: 325\n",
      "Total loss 0.13714 | Reg loss 0.13708\n",
      "Epoch 080: |  Loss: 0.00307 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2210 | Embeddings Left: 325\n",
      "Total loss 0.13711 | Reg loss 0.13705\n",
      "Epoch 081: |  Loss: 0.00317 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2210 | Embeddings Left: 325\n",
      "Total loss 0.13708 | Reg loss 0.13702\n",
      "Epoch 082: |  Loss: 0.00306 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2208 | Embeddings Left: 325\n",
      "Total loss 0.13705 | Reg loss 0.13699\n",
      "Epoch 083: |  Loss: 0.00313 | Acc: 0.998 | Val ACC: 0.892 | Features Left: 2205 | Embeddings Left: 325\n",
      "Total loss 0.13703 | Reg loss 0.13696\n",
      "Epoch 084: |  Loss: 0.00305 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2204 | Embeddings Left: 325\n",
      "Total loss 0.13700 | Reg loss 0.13694\n",
      "Epoch 085: |  Loss: 0.00317 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2201 | Embeddings Left: 325\n",
      "Total loss 0.13697 | Reg loss 0.13691\n",
      "Epoch 086: |  Loss: 0.00298 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2198 | Embeddings Left: 325\n",
      "Total loss 0.13694 | Reg loss 0.13688\n",
      "Epoch 087: |  Loss: 0.00320 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2198 | Embeddings Left: 325\n",
      "Total loss 0.13691 | Reg loss 0.13685\n",
      "Epoch 088: |  Loss: 0.00295 | Acc: 0.998 | Val ACC: 0.887 | Features Left: 2197 | Embeddings Left: 325\n",
      "Total loss 0.13688 | Reg loss 0.13682\n",
      "Epoch 089: |  Loss: 0.00326 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2196 | Embeddings Left: 325\n",
      "Total loss 0.13685 | Reg loss 0.13679\n",
      "Epoch 090: |  Loss: 0.00293 | Acc: 0.998 | Val ACC: 0.885 | Features Left: 2189 | Embeddings Left: 325\n",
      "Total loss 0.13682 | Reg loss 0.13676\n",
      "Epoch 091: |  Loss: 0.00329 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2189 | Embeddings Left: 325\n",
      "Total loss 0.13679 | Reg loss 0.13673\n",
      "Epoch 092: |  Loss: 0.00289 | Acc: 0.998 | Val ACC: 0.885 | Features Left: 2188 | Embeddings Left: 325\n",
      "Total loss 0.13676 | Reg loss 0.13670\n",
      "Epoch 093: |  Loss: 0.00360 | Acc: 0.998 | Val ACC: 0.890 | Features Left: 2188 | Embeddings Left: 325\n",
      "Total loss 0.13674 | Reg loss 0.13667\n",
      "Epoch 094: |  Loss: 0.00289 | Acc: 0.999 | Val ACC: 0.885 | Features Left: 2188 | Embeddings Left: 325\n",
      "Total loss 0.13671 | Reg loss 0.13664\n",
      "Epoch 095: |  Loss: 0.00401 | Acc: 0.999 | Val ACC: 0.890 | Features Left: 2186 | Embeddings Left: 325\n",
      "Total loss 0.13667 | Reg loss 0.13660\n",
      "Epoch 096: |  Loss: 0.00304 | Acc: 0.999 | Val ACC: 0.882 | Features Left: 2185 | Embeddings Left: 325\n",
      "Total loss 0.13666 | Reg loss 0.13657\n",
      "Epoch 097: |  Loss: 0.00432 | Acc: 0.999 | Val ACC: 0.887 | Features Left: 2184 | Embeddings Left: 325\n",
      "Total loss 0.13661 | Reg loss 0.13654\n",
      "Epoch 098: |  Loss: 0.00316 | Acc: 0.998 | Val ACC: 0.882 | Features Left: 2183 | Embeddings Left: 325\n",
      "Total loss 0.13660 | Reg loss 0.13651\n",
      "Epoch 099: |  Loss: 0.00431 | Acc: 0.999 | Val ACC: 0.887 | Features Left: 2181 | Embeddings Left: 325\n",
      "Total loss 0.13656 | Reg loss 0.13648\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Courier import SyncLocalCourier\n",
    "from VFLDataUtils import SimpleNumpyDataLoader\n",
    "from Client import SyncFNNClient\n",
    "torch.manual_seed(0)\n",
    "EMB_DIM = 128\n",
    "baselines_dualstg = {}\n",
    "for client_num in range(1, 6):\n",
    "    client_id_list = list(range(client_num))\n",
    "    courier = SyncLocalCourier(client_id_list)\n",
    "    loader = SimpleNumpyDataLoader(\n",
    "        clients_id_list=client_id_list,\n",
    "        data_source=(basehock_X, basehock_y)\n",
    "    )\n",
    "    loader_dict, input_dims = loader.distribute()\n",
    "    models, top_model = make_dual_stg_models(input_dims)\n",
    "    # for model in models: print(model)\n",
    "    # print(top_model)\n",
    "    clients = []\n",
    "    for i, id in enumerate(client_id_list):\n",
    "        client = SyncFNNClient(\n",
    "            id=id,\n",
    "            model= models[i],\n",
    "            courier=courier,\n",
    "            train_loader=loader_dict[id]['train_loader'],\n",
    "            test_loader=loader_dict[id]['test_loader'],\n",
    "            config_dir='simple_config.ini')\n",
    "        clients.append(client)\n",
    "    strategy = SyncDualSTGConcatStrategy(courier=courier, clients=clients)\n",
    "    server = SyncDualSTGServer(\n",
    "        strategy=strategy,\n",
    "        courier=courier,\n",
    "        top_model=top_model,\n",
    "        emb_model=models[-1],\n",
    "        train_loader=loader_dict['server']['train_loader'],\n",
    "        test_loader=loader_dict['server']['test_loader'],\n",
    "        config_dir='simple_config.ini')\n",
    "    \n",
    "    print('Training Starts')\n",
    "    print(f'Number of Clients: {client_num}')\n",
    "    print('-'*89)\n",
    "    for epoch in range(100):\n",
    "        server.fit(epoch)  \n",
    "    history = server.get_history()\n",
    "    baselines_dualstg[client_num] = history  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Number of Embeddings Never chages? That's pretty weired.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to two-party setting to investigate what's goring wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: Feature Index 0-2430\n",
      "Server : Feature Index 2431-4861\n"
     ]
    }
   ],
   "source": [
    "client_num = 1\n",
    "client_id_list = list(range(client_num))\n",
    "courier = SyncLocalCourier(client_id_list)\n",
    "loader = SimpleNumpyDataLoader(\n",
    "        clients_id_list=client_id_list,\n",
    "        data_source=(basehock_X, basehock_y)\n",
    "    )\n",
    "loader_dict, input_dims = loader.distribute()\n",
    "models, top_model = make_dual_stg_models(input_dims, top_lambda=0.5)\n",
    "clients = []\n",
    "for i, id in enumerate(client_id_list):\n",
    "    client = SyncFNNClient(\n",
    "        id=id,\n",
    "        model=models[i],\n",
    "        courier=courier,\n",
    "        train_loader=loader_dict[id]['train_loader'],\n",
    "        test_loader=loader_dict[id]['test_loader'],\n",
    "        config_dir='simple_config.ini')\n",
    "    clients.append(client)\n",
    "strategy = SyncDualSTGConcatStrategy(courier=courier, clients=clients)\n",
    "server = SyncDualSTGServer(\n",
    "        strategy=strategy,\n",
    "        courier=courier,\n",
    "        top_model=top_model,\n",
    "        emb_model=models[-1],\n",
    "        train_loader=loader_dict['server']['train_loader'],\n",
    "        test_loader=loader_dict['server']['test_loader'],\n",
    "        config_dir='simple_config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0109,  0.0007, -0.0126, -0.0075, -0.0115, -0.0081,  0.0063, -0.0012,\n",
       "         0.0062, -0.0042,  0.0113,  0.0065,  0.0140,  0.0137,  0.0094, -0.0143,\n",
       "         0.0043,  0.0052,  0.0018, -0.0017,  0.0089, -0.0033, -0.0054,  0.0219,\n",
       "         0.0071,  0.0048, -0.0002,  0.0183,  0.0085, -0.0028, -0.0008, -0.0025,\n",
       "         0.0006, -0.0105,  0.0007, -0.0018, -0.0145,  0.0031, -0.0157,  0.0212,\n",
       "         0.0130, -0.0010, -0.0075, -0.0044,  0.0082, -0.0041, -0.0035,  0.0077,\n",
       "        -0.0066, -0.0039, -0.0112, -0.0050,  0.0011,  0.0059,  0.0056,  0.0075,\n",
       "         0.0059,  0.0147, -0.0018, -0.0040, -0.0138,  0.0113, -0.0049,  0.0052,\n",
       "         0.0014, -0.0030,  0.0100, -0.0076, -0.0165, -0.0080, -0.0060,  0.0151,\n",
       "         0.0078,  0.0047,  0.0022,  0.0139,  0.0206,  0.0037,  0.0055,  0.0130,\n",
       "         0.0018, -0.0065,  0.0221,  0.0041, -0.0016,  0.0178,  0.0134, -0.0063,\n",
       "         0.0132,  0.0019,  0.0046, -0.0055,  0.0151,  0.0063, -0.0124, -0.0056,\n",
       "         0.0123,  0.0052,  0.0053,  0.0115,  0.0063, -0.0069, -0.0056,  0.0193,\n",
       "         0.0130,  0.0047,  0.0111,  0.0053, -0.0117,  0.0065, -0.0019, -0.0123,\n",
       "         0.0040,  0.0012,  0.0080,  0.0039, -0.0085, -0.0032, -0.0084, -0.0007,\n",
       "         0.0033,  0.0042,  0.0217, -0.0116,  0.0129, -0.0024,  0.0175,  0.0050],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients[0].model.top_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients[0].model.top_mu.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, num_embs = clients[0].model.get_emb_gates()\n",
    "num_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0516,  0.0087,  0.0462,  ...,  0.0474,  0.0000,  0.0869],\n",
       "        [-0.0192,  0.0493,  0.1121,  ..., -0.0560,  0.0000,  0.0630],\n",
       "        [ 0.0733,  0.0464,  0.1081,  ..., -0.0206,  0.0000,  0.1329],\n",
       "        ...,\n",
       "        [ 0.0272,  0.0411,  0.0009,  ..., -0.0218,  0.0000,  0.1326],\n",
       "        [ 0.0361,  0.0213,  0.0559,  ...,  0.0032,  0.0000,  0.0604],\n",
       "        [ 0.0557,  0.0433,  0.0070,  ..., -0.0170,  0.0000,  0.0951]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients[0].model(torch.randn(100, 2431).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0691, device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = clients[0].model.get_reg_loss() \n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients[0].model.top_mu.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients[0].optimizer.step()\n",
    "_, num_embs = clients[0].model.get_emb_gates()\n",
    "num_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 113 | Embeddings Left: 0\n",
      "Total loss 0.12736 | Reg loss 0.12735\n",
      "0 0\n",
      "Epoch 001: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 112 | Embeddings Left: 0\n",
      "Total loss 0.12710 | Reg loss 0.12709\n",
      "0 0\n",
      "Epoch 002: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 111 | Embeddings Left: 0\n",
      "Total loss 0.12685 | Reg loss 0.12684\n",
      "0 0\n",
      "Epoch 003: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 111 | Embeddings Left: 0\n",
      "Total loss 0.12659 | Reg loss 0.12658\n",
      "0 0\n",
      "Epoch 004: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 107 | Embeddings Left: 0\n",
      "Total loss 0.12633 | Reg loss 0.12632\n",
      "0 0\n",
      "Epoch 005: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 104 | Embeddings Left: 0\n",
      "Total loss 0.12607 | Reg loss 0.12606\n",
      "0 0\n",
      "Epoch 006: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 100 | Embeddings Left: 0\n",
      "Total loss 0.12581 | Reg loss 0.12580\n",
      "0 0\n",
      "Epoch 007: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 99 | Embeddings Left: 0\n",
      "Total loss 0.12554 | Reg loss 0.12553\n",
      "0 0\n",
      "Epoch 008: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 97 | Embeddings Left: 0\n",
      "Total loss 0.12528 | Reg loss 0.12527\n",
      "0 0\n",
      "Epoch 009: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 95 | Embeddings Left: 0\n",
      "Total loss 0.12501 | Reg loss 0.12500\n",
      "0 0\n",
      "Epoch 010: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 93 | Embeddings Left: 0\n",
      "Total loss 0.12474 | Reg loss 0.12473\n",
      "0 0\n",
      "Epoch 011: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 91 | Embeddings Left: 0\n",
      "Total loss 0.12447 | Reg loss 0.12446\n",
      "0 0\n",
      "Epoch 012: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 88 | Embeddings Left: 0\n",
      "Total loss 0.12420 | Reg loss 0.12419\n",
      "0 0\n",
      "Epoch 013: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 87 | Embeddings Left: 0\n",
      "Total loss 0.12393 | Reg loss 0.12392\n",
      "0 0\n",
      "Epoch 014: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 84 | Embeddings Left: 0\n",
      "Total loss 0.12365 | Reg loss 0.12365\n",
      "0 0\n",
      "Epoch 015: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 81 | Embeddings Left: 0\n",
      "Total loss 0.12338 | Reg loss 0.12337\n",
      "0 0\n",
      "Epoch 016: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 78 | Embeddings Left: 0\n",
      "Total loss 0.12311 | Reg loss 0.12310\n",
      "0 0\n",
      "Epoch 017: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 77 | Embeddings Left: 0\n",
      "Total loss 0.12283 | Reg loss 0.12282\n",
      "0 0\n",
      "Epoch 018: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 76 | Embeddings Left: 0\n",
      "Total loss 0.12255 | Reg loss 0.12254\n",
      "0 0\n",
      "Epoch 019: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 76 | Embeddings Left: 0\n",
      "Total loss 0.12227 | Reg loss 0.12227\n",
      "0 0\n",
      "Epoch 020: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 74 | Embeddings Left: 0\n",
      "Total loss 0.12200 | Reg loss 0.12199\n",
      "0 0\n",
      "Epoch 021: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 71 | Embeddings Left: 0\n",
      "Total loss 0.12172 | Reg loss 0.12171\n",
      "0 0\n",
      "Epoch 022: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 70 | Embeddings Left: 0\n",
      "Total loss 0.12143 | Reg loss 0.12143\n",
      "0 0\n",
      "Epoch 023: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 70 | Embeddings Left: 0\n",
      "Total loss 0.12115 | Reg loss 0.12114\n",
      "0 0\n",
      "Epoch 024: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 70 | Embeddings Left: 0\n",
      "Total loss 0.12087 | Reg loss 0.12086\n",
      "0 0\n",
      "Epoch 025: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 68 | Embeddings Left: 0\n",
      "Total loss 0.12059 | Reg loss 0.12058\n",
      "0 0\n",
      "Epoch 026: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 67 | Embeddings Left: 0\n",
      "Total loss 0.12030 | Reg loss 0.12030\n",
      "0 0\n",
      "Epoch 027: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 65 | Embeddings Left: 0\n",
      "Total loss 0.12002 | Reg loss 0.12001\n",
      "0 0\n",
      "Epoch 028: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 65 | Embeddings Left: 0\n",
      "Total loss 0.11974 | Reg loss 0.11973\n",
      "0 0\n",
      "Epoch 029: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 64 | Embeddings Left: 0\n",
      "Total loss 0.11945 | Reg loss 0.11944\n",
      "0 0\n",
      "Epoch 030: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 63 | Embeddings Left: 0\n",
      "Total loss 0.11917 | Reg loss 0.11916\n",
      "0 0\n",
      "Epoch 031: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 63 | Embeddings Left: 0\n",
      "Total loss 0.11888 | Reg loss 0.11887\n",
      "0 0\n",
      "Epoch 032: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 61 | Embeddings Left: 0\n",
      "Total loss 0.11859 | Reg loss 0.11859\n",
      "0 0\n",
      "Epoch 033: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 60 | Embeddings Left: 0\n",
      "Total loss 0.11831 | Reg loss 0.11830\n",
      "0 0\n",
      "Epoch 034: |  Loss: 0.00004 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 60 | Embeddings Left: 0\n",
      "Total loss 0.11802 | Reg loss 0.11801\n",
      "0 0\n",
      "Epoch 035: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 59 | Embeddings Left: 0\n",
      "Total loss 0.11773 | Reg loss 0.11772\n",
      "0 0\n",
      "Epoch 036: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 57 | Embeddings Left: 0\n",
      "Total loss 0.11744 | Reg loss 0.11743\n",
      "0 0\n",
      "Epoch 037: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 55 | Embeddings Left: 0\n",
      "Total loss 0.11715 | Reg loss 0.11714\n",
      "0 0\n",
      "Epoch 038: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 53 | Embeddings Left: 0\n",
      "Total loss 0.11686 | Reg loss 0.11685\n",
      "0 0\n",
      "Epoch 039: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.965 | Features Left: 51 | Embeddings Left: 0\n",
      "Total loss 0.11657 | Reg loss 0.11656\n",
      "0 0\n",
      "Epoch 040: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.965 | Features Left: 51 | Embeddings Left: 0\n",
      "Total loss 0.11628 | Reg loss 0.11627\n",
      "0 0\n",
      "Epoch 041: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.965 | Features Left: 51 | Embeddings Left: 0\n",
      "Total loss 0.11599 | Reg loss 0.11598\n",
      "0 0\n",
      "Epoch 042: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.965 | Features Left: 51 | Embeddings Left: 0\n",
      "Total loss 0.11570 | Reg loss 0.11569\n",
      "0 0\n",
      "Epoch 043: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.967 | Features Left: 51 | Embeddings Left: 0\n",
      "Total loss 0.11540 | Reg loss 0.11540\n",
      "0 0\n",
      "Epoch 044: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.970 | Features Left: 51 | Embeddings Left: 0\n",
      "Total loss 0.11511 | Reg loss 0.11511\n",
      "0 0\n",
      "Epoch 045: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.970 | Features Left: 48 | Embeddings Left: 0\n",
      "Total loss 0.11482 | Reg loss 0.11482\n",
      "0 0\n",
      "Epoch 046: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.970 | Features Left: 47 | Embeddings Left: 0\n",
      "Total loss 0.11453 | Reg loss 0.11453\n",
      "0 0\n",
      "Epoch 047: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.970 | Features Left: 45 | Embeddings Left: 0\n",
      "Total loss 0.11424 | Reg loss 0.11424\n",
      "0 0\n",
      "Epoch 048: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.970 | Features Left: 44 | Embeddings Left: 0\n",
      "Total loss 0.11395 | Reg loss 0.11395\n",
      "0 0\n",
      "Epoch 049: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.970 | Features Left: 43 | Embeddings Left: 0\n",
      "Total loss 0.11366 | Reg loss 0.11366\n",
      "0 0\n",
      "Epoch 050: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.970 | Features Left: 42 | Embeddings Left: 0\n",
      "Total loss 0.11338 | Reg loss 0.11337\n",
      "0 0\n",
      "Epoch 051: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.970 | Features Left: 41 | Embeddings Left: 0\n",
      "Total loss 0.11309 | Reg loss 0.11308\n",
      "0 0\n",
      "Epoch 052: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.970 | Features Left: 41 | Embeddings Left: 0\n",
      "Total loss 0.11280 | Reg loss 0.11279\n",
      "0 0\n",
      "Epoch 053: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.967 | Features Left: 41 | Embeddings Left: 0\n",
      "Total loss 0.11251 | Reg loss 0.11251\n",
      "0 0\n",
      "Epoch 054: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.967 | Features Left: 41 | Embeddings Left: 0\n",
      "Total loss 0.11222 | Reg loss 0.11222\n",
      "0 0\n",
      "Epoch 055: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.967 | Features Left: 41 | Embeddings Left: 0\n",
      "Total loss 0.11194 | Reg loss 0.11193\n",
      "0 0\n",
      "Epoch 056: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.967 | Features Left: 40 | Embeddings Left: 0\n",
      "Total loss 0.11165 | Reg loss 0.11165\n",
      "0 0\n",
      "Epoch 057: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.967 | Features Left: 40 | Embeddings Left: 0\n",
      "Total loss 0.11137 | Reg loss 0.11136\n",
      "0 0\n",
      "Epoch 058: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.965 | Features Left: 40 | Embeddings Left: 0\n",
      "Total loss 0.11108 | Reg loss 0.11108\n",
      "0 0\n",
      "Epoch 059: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 37 | Embeddings Left: 0\n",
      "Total loss 0.11080 | Reg loss 0.11080\n",
      "0 0\n",
      "Epoch 060: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.965 | Features Left: 37 | Embeddings Left: 0\n",
      "Total loss 0.11052 | Reg loss 0.11051\n",
      "0 0\n",
      "Epoch 061: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 37 | Embeddings Left: 0\n",
      "Total loss 0.11024 | Reg loss 0.11023\n",
      "0 0\n",
      "Epoch 062: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 35 | Embeddings Left: 0\n",
      "Total loss 0.10996 | Reg loss 0.10995\n",
      "0 0\n",
      "Epoch 063: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 35 | Embeddings Left: 0\n",
      "Total loss 0.10968 | Reg loss 0.10968\n",
      "0 0\n",
      "Epoch 064: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 35 | Embeddings Left: 0\n",
      "Total loss 0.10941 | Reg loss 0.10940\n",
      "0 0\n",
      "Epoch 065: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 35 | Embeddings Left: 0\n",
      "Total loss 0.10913 | Reg loss 0.10912\n",
      "0 0\n",
      "Epoch 066: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 34 | Embeddings Left: 0\n",
      "Total loss 0.10886 | Reg loss 0.10885\n",
      "0 0\n",
      "Epoch 067: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 34 | Embeddings Left: 0\n",
      "Total loss 0.10858 | Reg loss 0.10858\n",
      "0 0\n",
      "Epoch 068: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 34 | Embeddings Left: 0\n",
      "Total loss 0.10831 | Reg loss 0.10830\n",
      "0 0\n",
      "Epoch 069: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 34 | Embeddings Left: 0\n",
      "Total loss 0.10804 | Reg loss 0.10803\n",
      "0 0\n",
      "Epoch 070: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 34 | Embeddings Left: 0\n",
      "Total loss 0.10777 | Reg loss 0.10776\n",
      "0 0\n",
      "Epoch 071: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 34 | Embeddings Left: 0\n",
      "Total loss 0.10750 | Reg loss 0.10749\n",
      "0 0\n",
      "Epoch 072: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 34 | Embeddings Left: 0\n",
      "Total loss 0.10723 | Reg loss 0.10722\n",
      "0 0\n",
      "Epoch 073: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 34 | Embeddings Left: 0\n",
      "Total loss 0.10696 | Reg loss 0.10695\n",
      "0 0\n",
      "Epoch 074: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 32 | Embeddings Left: 0\n",
      "Total loss 0.10669 | Reg loss 0.10668\n",
      "0 0\n",
      "Epoch 075: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 31 | Embeddings Left: 0\n",
      "Total loss 0.10642 | Reg loss 0.10641\n",
      "0 0\n",
      "Epoch 076: |  Loss: 0.00003 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 29 | Embeddings Left: 0\n",
      "Total loss 0.10615 | Reg loss 0.10615\n",
      "0 0\n",
      "Epoch 077: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 29 | Embeddings Left: 0\n",
      "Total loss 0.10588 | Reg loss 0.10588\n",
      "0 0\n",
      "Epoch 078: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 29 | Embeddings Left: 0\n",
      "Total loss 0.10562 | Reg loss 0.10561\n",
      "0 0\n",
      "Epoch 079: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.962 | Features Left: 28 | Embeddings Left: 0\n",
      "Total loss 0.10535 | Reg loss 0.10535\n",
      "0 0\n",
      "Epoch 080: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 28 | Embeddings Left: 0\n",
      "Total loss 0.10509 | Reg loss 0.10508\n",
      "0 0\n",
      "Epoch 081: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 28 | Embeddings Left: 0\n",
      "Total loss 0.10483 | Reg loss 0.10482\n",
      "0 0\n",
      "Epoch 082: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 28 | Embeddings Left: 0\n",
      "Total loss 0.10456 | Reg loss 0.10456\n",
      "0 0\n",
      "Epoch 083: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 27 | Embeddings Left: 0\n",
      "Total loss 0.10430 | Reg loss 0.10430\n",
      "0 0\n",
      "Epoch 084: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 27 | Embeddings Left: 0\n",
      "Total loss 0.10404 | Reg loss 0.10404\n",
      "0 0\n",
      "Epoch 085: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 27 | Embeddings Left: 0\n",
      "Total loss 0.10379 | Reg loss 0.10378\n",
      "0 0\n",
      "Epoch 086: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 27 | Embeddings Left: 0\n",
      "Total loss 0.10353 | Reg loss 0.10352\n",
      "0 0\n",
      "Epoch 087: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 27 | Embeddings Left: 0\n",
      "Total loss 0.10327 | Reg loss 0.10327\n",
      "0 0\n",
      "Epoch 088: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 27 | Embeddings Left: 0\n",
      "Total loss 0.10302 | Reg loss 0.10301\n",
      "0 0\n",
      "Epoch 089: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 27 | Embeddings Left: 0\n",
      "Total loss 0.10277 | Reg loss 0.10276\n",
      "0 0\n",
      "Epoch 090: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 27 | Embeddings Left: 0\n",
      "Total loss 0.10251 | Reg loss 0.10251\n",
      "0 0\n",
      "Epoch 091: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 26 | Embeddings Left: 0\n",
      "Total loss 0.10226 | Reg loss 0.10226\n",
      "0 0\n",
      "Epoch 092: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 23 | Embeddings Left: 0\n",
      "Total loss 0.10201 | Reg loss 0.10200\n",
      "0 0\n",
      "Epoch 093: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 23 | Embeddings Left: 0\n",
      "Total loss 0.10176 | Reg loss 0.10175\n",
      "0 0\n",
      "Epoch 094: |  Loss: 0.00002 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 23 | Embeddings Left: 0\n",
      "Total loss 0.10151 | Reg loss 0.10150\n",
      "0 0\n",
      "Epoch 095: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.960 | Features Left: 23 | Embeddings Left: 0\n",
      "Total loss 0.10126 | Reg loss 0.10125\n",
      "0 0\n",
      "Epoch 096: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 22 | Embeddings Left: 0\n",
      "Total loss 0.10101 | Reg loss 0.10100\n",
      "0 0\n",
      "Epoch 097: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.957 | Features Left: 22 | Embeddings Left: 0\n",
      "Total loss 0.10076 | Reg loss 0.10075\n",
      "0 0\n",
      "Epoch 098: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 22 | Embeddings Left: 0\n",
      "Total loss 0.10051 | Reg loss 0.10051\n",
      "0 0\n",
      "Epoch 099: |  Loss: 0.00001 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 22 | Embeddings Left: 0\n",
      "Total loss 0.10026 | Reg loss 0.10026\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    server.fit(epoch)\n",
    "    # print('Client', clients[0].model.top_mu.grad)\n",
    "    _, num_embs = clients[0].model.get_emb_gates()\n",
    "    _, num_feats = clients[0].model.get_gates()\n",
    "    print(num_embs, num_feats)\n",
    "    # print('Sever', server.emb_model.top_mu.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(server.gates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_gates, btm_gates = server.gates[0]\n",
    "top_gate = top_gates[0]\n",
    "sns.heatmap(top_gate.reshape(16, 8), vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_gates, btm_gates = server.gates[-1]\n",
    "top_gate = top_gates[0]\n",
    "sns.heatmap(top_gate.reshape(16, 8), vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyncDualSTGClient(SyncFNNClient):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.optimizer = torch.optim.SGD([\n",
    "                {'params': model.fs.parameters(), 'lr': 1e-3},\n",
    "                {'params': model.top_fs.parameters(), 'lr': 1e-3},\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: Feature Index 0-2430\n",
      "Server : Feature Index 2431-4861\n"
     ]
    }
   ],
   "source": [
    "client_num = 1\n",
    "client_id_list = list(range(client_num))\n",
    "courier = SyncLocalCourier(client_id_list)\n",
    "loader = SimpleNumpyDataLoader(\n",
    "        clients_id_list=client_id_list,\n",
    "        data_source=(basehock_X, basehock_y)\n",
    "    )\n",
    "loader_dict, input_dims = loader.distribute()\n",
    "models, top_model = make_dual_stg_models(input_dims, top_lambda=100)\n",
    "clients = []\n",
    "for i, id in enumerate(client_id_list):\n",
    "    client = SyncDualSTGClient(\n",
    "        id=id,\n",
    "        model=models[i],\n",
    "        courier=courier,\n",
    "        train_loader=loader_dict[id]['train_loader'],\n",
    "        test_loader=loader_dict[id]['test_loader'],\n",
    "        config_dir='simple_config.ini')\n",
    "    clients.append(client)\n",
    "strategy = SyncDualSTGConcatStrategy(courier=courier, clients=clients)\n",
    "server = SyncDualSTGServer(\n",
    "        strategy=strategy,\n",
    "        courier=courier,\n",
    "        top_model=top_model,\n",
    "        emb_model=models[-1],\n",
    "        train_loader=loader_dict['server']['train_loader'],\n",
    "        test_loader=loader_dict['server']['test_loader'],\n",
    "        config_dir='simple_config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DualSTGModel(\n",
       "  (mlp): MLPLayer(\n",
       "    (mlp): Sequential(\n",
       "      (0): LinearLayer(\n",
       "        (0): Linear(in_features=2431, out_features=512, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): LinearLayer(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fs): FeatureSelector()\n",
       "  (top_fs): FeatureSelector()\n",
       ")"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients[0].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: |  Loss: 0.00019 | Acc: 1.000 | Val ACC: 0.952 | Features Left: 267 | Embeddings Left: 3\n",
      "Total loss 43.83442 | Reg loss 43.83435\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 001: |  Loss: 0.00017 | Acc: 1.000 | Val ACC: 0.952 | Features Left: 266 | Embeddings Left: 3\n",
      "Total loss 43.69934 | Reg loss 43.69927\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 002: |  Loss: 0.00017 | Acc: 1.000 | Val ACC: 0.952 | Features Left: 265 | Embeddings Left: 3\n",
      "Total loss 43.56622 | Reg loss 43.56615\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 003: |  Loss: 0.00017 | Acc: 1.000 | Val ACC: 0.952 | Features Left: 261 | Embeddings Left: 3\n",
      "Total loss 43.43505 | Reg loss 43.43498\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 004: |  Loss: 0.00017 | Acc: 1.000 | Val ACC: 0.952 | Features Left: 258 | Embeddings Left: 3\n",
      "Total loss 43.30577 | Reg loss 43.30572\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 005: |  Loss: 0.00017 | Acc: 1.000 | Val ACC: 0.952 | Features Left: 255 | Embeddings Left: 3\n",
      "Total loss 43.17842 | Reg loss 43.17834\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 006: |  Loss: 0.00016 | Acc: 1.000 | Val ACC: 0.952 | Features Left: 254 | Embeddings Left: 3\n",
      "Total loss 43.05291 | Reg loss 43.05283\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 007: |  Loss: 0.00016 | Acc: 1.000 | Val ACC: 0.952 | Features Left: 250 | Embeddings Left: 3\n",
      "Total loss 42.92924 | Reg loss 42.92918\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 008: |  Loss: 0.00016 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 249 | Embeddings Left: 3\n",
      "Total loss 42.80742 | Reg loss 42.80734\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 009: |  Loss: 0.00016 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 249 | Embeddings Left: 3\n",
      "Total loss 42.68738 | Reg loss 42.68732\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 010: |  Loss: 0.00015 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 249 | Embeddings Left: 3\n",
      "Total loss 42.56911 | Reg loss 42.56907\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 011: |  Loss: 0.00015 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 247 | Embeddings Left: 3\n",
      "Total loss 42.45266 | Reg loss 42.45262\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 012: |  Loss: 0.00014 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 247 | Embeddings Left: 3\n",
      "Total loss 42.33791 | Reg loss 42.33786\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 013: |  Loss: 0.00015 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 245 | Embeddings Left: 3\n",
      "Total loss 42.22490 | Reg loss 42.22485\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Epoch 014: |  Loss: 0.00015 | Acc: 1.000 | Val ACC: 0.955 | Features Left: 244 | Embeddings Left: 3\n",
      "Total loss 42.11359 | Reg loss 42.11353\n",
      "Client Parameter containing:\n",
      "tensor([-2.0625e-02, -2.4356e-03, -3.5375e-02, -2.7794e-02, -1.4490e-02,\n",
      "        -1.5558e-02, -1.5959e-02, -2.3139e-02, -2.5749e-02,  7.5490e-04,\n",
      "        -2.7766e-02, -2.5354e-02, -1.9160e-02, -3.3089e-02, -1.3248e-02,\n",
      "        -1.1428e-02, -2.7769e-02, -1.4361e-02,  9.3146e-03, -1.9690e-02,\n",
      "        -5.7924e-03, -1.6099e-02, -8.7701e-03, -2.9552e-02, -1.5436e-02,\n",
      "        -1.7982e-02, -2.2693e-02, -2.3228e-02, -3.2061e-02, -2.0025e-02,\n",
      "        -1.1104e-02, -2.9806e-02, -2.1174e-02, -2.3379e-02, -3.7930e-02,\n",
      "        -2.4234e-02, -8.7241e-03, -2.4329e-02, -8.8785e-03, -3.8360e-02,\n",
      "        -2.1154e-02, -1.7360e-02, -2.8186e-02, -1.8846e-02, -1.8851e-02,\n",
      "        -1.9879e-02, -2.9825e-02, -2.2145e-02, -1.5811e-02, -1.1532e-02,\n",
      "        -1.2267e-02, -3.0718e-02, -2.7948e-02, -1.8112e-02, -2.4702e-02,\n",
      "        -1.9687e-02, -1.9627e-02, -3.2367e-02, -8.4757e-03, -2.2909e-02,\n",
      "        -1.8149e-02, -1.6704e-02, -2.9131e-02, -1.8055e-02, -1.4737e-02,\n",
      "        -2.2352e-02, -2.9645e-02, -7.4058e-05, -1.6472e-02, -1.8304e-02,\n",
      "        -2.4241e-02, -3.0429e-02, -1.1178e-02, -1.7849e-02, -3.6056e-02,\n",
      "        -2.9782e-02, -1.6491e-02, -2.3570e-02, -3.3518e-02, -2.9818e-02,\n",
      "        -9.5183e-03, -2.0941e-02, -4.7236e-03, -7.6985e-03, -1.0114e-03,\n",
      "        -2.1448e-02, -1.2853e-02, -1.7246e-02, -1.5141e-02, -1.5939e-02,\n",
      "        -3.7335e-02, -1.8492e-02, -1.8996e-02, -1.5308e-02, -3.0062e-02,\n",
      "        -1.7467e-02, -2.6120e-02, -1.3221e-02, -1.4309e-02,  1.5406e-02,\n",
      "        -1.4118e-02, -1.0544e-02, -2.2964e-02, -2.3705e-02, -4.9816e-03,\n",
      "        -3.2436e-02, -3.4652e-02, -1.8104e-02, -3.8883e-02, -1.0453e-02,\n",
      "        -2.6572e-02, -5.3079e-03, -1.3685e-02, -2.3417e-02, -1.7914e-02,\n",
      "        -1.2583e-02, -1.0456e-02, -2.1035e-02, -3.0376e-02, -2.7089e-02,\n",
      "        -8.7500e-03, -1.1674e-02, -1.7198e-02, -1.3863e-02, -2.4175e-02,\n",
      "        -5.5810e-03, -1.6014e-02, -2.9787e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Client Parameter containing:\n",
      "tensor([-0.0053, -0.0246, -0.0288,  ..., -0.0124, -0.0352, -0.0101],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "new_optimizer = torch.optim.Adam(list(clients[0].model.top_fs.parameters()) + \n",
    "list(clients[0].model.fs.parameters()), lr=1e-3)\n",
    "for epoch in range(15):\n",
    "    server.fit(epoch)\n",
    "    print('Client', clients[0].model.top_mu)\n",
    "    print('Client', clients[0].model.mu)\n",
    "    if epoch > 80:\n",
    "        new_optimizer.step()\n",
    "    # print('Sever', server.emb_model.top_mu.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_gates, btm_gates = server.gates[0]\n",
    "top_gate = top_gates[0]\n",
    "sns.heatmap(top_gate.reshape(16, 8), vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_gates, btm_gates = server.gates[-1]\n",
    "top_gate = top_gates[0]\n",
    "sns.heatmap(top_gate.reshape(16, 8), vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, btm_gates = server.gates[0]\n",
    "btm_gate = btm_gates[0]\n",
    "sns.heatmap(btm_gate.reshape(2431, 1), vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, btm_gates = server.gates[-1]\n",
    "btm_gate = btm_gates[0]\n",
    "sns.heatmap(btm_gate.reshape(2431, 1), vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " 0)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server.emb_model.get_emb_gates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basehock_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 250)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server.emb_model.get_gates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.001\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    dampening: 0\n",
       "    lr: 1\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients[0].optimizer"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1579d4a348c2ef16482c05d3cfac916f73c8945ddf1938a1e045b3bdea82eece"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('VFL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
